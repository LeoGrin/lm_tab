{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loading import load_data\n",
    "from skrub import MinHashEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from src.utils import FeaturesExtractor, FixedSizeSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(X, encoder_name):\n",
    "    if isinstance(X, pd.DataFrame) or isinstance(X, pd.Series):\n",
    "        X = np.array(X)\n",
    "    encoder_type, encoder_params = encoder_name.split(\"__\", 1)\n",
    "    if encoder_type == \"lm\":\n",
    "        encoder = SentenceTransformer(encoder_params)\n",
    "        return encoder.encode(X)\n",
    "    elif encoder_type == \"skrub\":\n",
    "        if encoder_params.startswith(\"minhash\"):\n",
    "            n_components = int(encoder_params.split(\"_\")[1])\n",
    "            encoder = MinHashEncoder(n_components=n_components)\n",
    "            # reshape to 2d array\n",
    "            # if pandas dataframe, convert to numpy array\n",
    "            X = X.reshape(-1, 1)\n",
    "            return encoder.fit_transform(X)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown skrub encoder {encoder_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/lgrinszt/lm_tab/scripts\n"
     ]
    }
   ],
   "source": [
    "%cd lm_tab/scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/lgrinszt/lm_tab/scripts\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original task: classification for spotify\n"
     ]
    }
   ],
   "source": [
    "# compare speed on cpu and gpu\n",
    "X, y = load_data(\"spotify\", max_rows=10000)\n",
    "# label encoding\n",
    "#y = y.astype('category').cat.codes\n",
    "y = y.astype(np.int64)\n",
    "#X_enc = encode(X, \"lm__all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from tabpfn import TabPFNClassifier\n",
    "from src.utils import preprocess_input\n",
    "from transformers import AutoModel\n",
    "class BertAndTabPFN(nn.Module):\n",
    "    def __init__(self, linear_translator=False, dim_tabpfn=100, preprocess_before_tabpfn=False,\n",
    "                 train_tabpfn=False, transformer_name=\"distilroberta-base\"):\n",
    "        super().__init__()\n",
    "        #self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        #self.bert = BertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.bert = AutoModel.from_pretrained(transformer_name)\n",
    "        self.raw_tabpfn = TabPFNClassifier()\n",
    "        self.tabpfn = self.raw_tabpfn.model[2]\n",
    "        if not train_tabpfn:\n",
    "            # no requires_grad for the tabpfn\n",
    "            for param in self.tabpfn.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.dim_tabpfn = dim_tabpfn\n",
    "        self.preprocess_before_tabpfn = preprocess_before_tabpfn\n",
    "        if linear_translator:\n",
    "            self.linear_translator = nn.Linear(768, dim_tabpfn)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, y, tabular_data=None, single_eval_pos=100, return_tabpfn_input=False):\n",
    "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        bert_embeddings = bert_outputs.last_hidden_state[:, 0, :]\n",
    "        if hasattr(self, 'linear_translator'):\n",
    "            tabpfn_input = self.linear_translator(bert_embeddings)\n",
    "        else:\n",
    "            tabpfn_input = bert_embeddings[:, :self.dim_tabpfn]\n",
    "        if return_tabpfn_input:\n",
    "            return tabpfn_input\n",
    "        tabpfn_input = tabpfn_input.reshape(tabpfn_input.shape[0], 1, tabpfn_input.shape[1])\n",
    "        if self.preprocess_before_tabpfn:\n",
    "            tabpfn_input = preprocess_input(tabpfn_input, y, single_eval_pos, preprocess_transform=\"none\", device=input_ids.device)\n",
    "        y = y.reshape(y.shape[0], 1)\n",
    "        tabpfn_outputs = self.tabpfn((tabpfn_input, y), single_eval_pos=single_eval_pos)\n",
    "        return tabpfn_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.utils import preprocess_input\n",
    "from icecream import ic\n",
    "\n",
    "# Create a custom dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "\n",
    "def evaluate_model(dataloader, model, input_ids_train, attention_mask_train, labels_train):\n",
    "    print(\"Evaluating model\")\n",
    "    model.eval()\n",
    "    val_preds, val_labels, val_losses = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader: #TODO: remove the useless for loop\n",
    "            input_ids_val = batch['input_ids']\n",
    "            attention_mask_val = batch['attention_mask']\n",
    "            labels_val = batch['labels']\n",
    "            # move the inputs to GPU\n",
    "            input_ids_val = input_ids_val.to('cuda')\n",
    "            attention_mask_val = attention_mask_val.to('cuda')\n",
    "            labels_val = labels_val.to('cuda')\n",
    "            # concatenate train and val\n",
    "            #TODO: make sure this is correct, no leak etc\n",
    "            # maybe safer to create a TabPFNClassifier with the same parameters as the one in BertAndTabPFN\n",
    "            input_ids = torch.cat((input_ids_train, input_ids_val), axis=0)\n",
    "            attention_mask = torch.cat((attention_mask_train, attention_mask_val), axis=0)\n",
    "            labels = torch.cat((labels_train, labels_val), axis=0)\n",
    "            single_eval_pos = len(input_ids_train)\n",
    "            print(f\"Train size: {len(input_ids_train)}, Val size: {len(input_ids_val)}\")\n",
    "            output = model(input_ids, attention_mask=attention_mask, y=labels, single_eval_pos=single_eval_pos).squeeze()\n",
    "            val_loss = nn.CrossEntropyLoss()(output, labels[single_eval_pos:].long().reshape(-1))\n",
    "            val_losses.append(val_loss.cpu())\n",
    "            preds = torch.argmax(output, axis=-1).cpu().detach().numpy()\n",
    "            val_preds.append(preds)\n",
    "            val_labels.append(labels[single_eval_pos:].cpu().detach().numpy().reshape(-1))\n",
    "        val_preds = np.concatenate(val_preds)\n",
    "        val_labels = np.concatenate(val_labels)\n",
    "        loss = np.mean(val_losses)\n",
    "        accuracy = accuracy_score(val_labels, val_preds)\n",
    "    \n",
    "    # try with tabpfn classifier to see if there is a difference\n",
    "    # tabfn_input_train = model(input_ids_train, attention_mask=attention_mask_train, y=labels_train, single_eval_pos=single_eval_pos, return_tabpfn_input=True).cpu().detach().numpy()\n",
    "    # clf = model.raw_tabpfn\n",
    "    # clf.fit(tabfn_input_train, labels_train.cpu().detach().numpy())\n",
    "    # tabfn_input_val = model(input_ids_val, attention_mask=attention_mask_val, y=labels_val, single_eval_pos=single_eval_pos, return_tabpfn_input=True).cpu().detach().numpy()\n",
    "    # val_preds = clf.predict(tabfn_input_val)\n",
    "    # val_labels = labels_val.cpu().detach().numpy()\n",
    "    # accuracy_clf = accuracy_score(val_labels, val_preds)\n",
    "    # print(f\"Accuracy with tabpfn classifier: {accuracy_clf}\")\n",
    "    # print(f\"Accuracy raw: {accuracy}\")\n",
    "    # # move back to cuda\n",
    "\n",
    "        \n",
    "    model.train()\n",
    "    return loss, accuracy\n",
    "    \n",
    "\n",
    "def train_model(X_enc_dic, y, transformer_name=\"distilroberta-base\"):\n",
    "    \n",
    "\n",
    "\n",
    "    train_size = int(0.8 * len(X_enc_dic[\"input_ids\"]))\n",
    "    val_size = len(X_enc_dic[\"input_ids\"]) - train_size\n",
    "    print(f\"Train size: {train_size}, Val size: {val_size}\")\n",
    "    X_train, X_val = {k: v[:train_size] for k, v in X_enc_dic.items()}, {k: v[train_size:] for k, v in X_enc_dic.items()}\n",
    "    y_train, y_val = y[:train_size], y[train_size:]\n",
    "    train_dataset = CustomDataset(X_train, torch.tensor(y_train).float().reshape(-1, 1))\n",
    "    val_dataset = CustomDataset(X_val, torch.tensor(y_val).float().reshape(-1, 1))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    #model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "    model = BertAndTabPFN(preprocess_before_tabpfn=True, linear_translator=False, transformer_name=transformer_name).to('cuda')\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    es_patience = 3\n",
    "    es_tolerance = 1e-4\n",
    "    es_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 20\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(num_epochs):\n",
    "        if es_counter >= es_patience:\n",
    "            break\n",
    "        ###########\n",
    "        # Train loop\n",
    "        model.train()\n",
    "        train_preds, train_labels, train_losses = [], [], []\n",
    "        for batch in train_loader:\n",
    "            input_ids_train = batch['input_ids']\n",
    "            attention_mask_train = batch['attention_mask']\n",
    "            labels_train = batch['labels']\n",
    "            # move the inputs to GPU\n",
    "            input_ids_train = input_ids_train.to('cuda')\n",
    "            attention_mask_train = attention_mask_train.to('cuda')\n",
    "            labels_train = labels_train.to('cuda')\n",
    "            single_eval_pos = 400\n",
    "            output = model(input_ids_train, attention_mask=attention_mask_train, y=labels_train, single_eval_pos=single_eval_pos).squeeze()\n",
    "            loss = nn.CrossEntropyLoss()(output, labels_train[single_eval_pos:].long().reshape(-1))\n",
    "            if epoch > 0: #TODO: remove this, this is just for testing\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            # compute train accuracy\n",
    "            preds = torch.argmax(output, axis=-1).cpu().detach().numpy()\n",
    "            train_losses.append(loss.cpu().item())\n",
    "            train_preds.append(preds)\n",
    "            train_labels.append(labels_train[single_eval_pos:].cpu().detach().numpy().reshape(-1))\n",
    "        train_preds = np.concatenate(train_preds)\n",
    "        train_labels = np.concatenate(train_labels)\n",
    "        train_losses = np.mean(train_losses)\n",
    "        print(f\"Epoch {epoch + 1} - Training loss: {train_losses}, Training accuracy: {accuracy_score(train_labels, train_preds)}\")\n",
    "        # Validation loop\n",
    "        val_loss, val_accuracy = evaluate_model(val_loader, model, input_ids_train, attention_mask_train, labels_train)\n",
    "        print(f\"Epoch {epoch + 1} - Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n",
    "        if val_loss < best_val_loss - es_tolerance:\n",
    "            print(f\"Validation loss decreased from {best_val_loss} to {val_loss}\")\n",
    "            best_val_loss = val_loss\n",
    "            # save the model\n",
    "            torch.save(model.state_dict(), \"checkpoints/model.pt\")\n",
    "            # save input_ids_train, attention_mask_train, labels_train\n",
    "            #torch.save(input_ids_train, \"checkpoints/input_ids_train.pt\")\n",
    "            #torch.save(attention_mask_train, \"checkpoints/attention_mask_train.pt\")\n",
    "            #torch.save(labels_train, \"checkpoints/labels_train.pt\")\n",
    "        else:\n",
    "            es_counter += 1\n",
    "            print(f\"Early stopping counter: {es_counter}\")\n",
    "            if es_counter >= es_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load(\"checkpoints/model.pt\"))\n",
    "    #input_ids_train = torch.load(\"checkpoints/input_ids_train.pt\")\n",
    "    #attention_mask_train = torch.load(\"checkpoints/attention_mask_train.pt\")\n",
    "    #labels_train = torch.load(\"checkpoints/labels_train.pt\")\n",
    "    # concatenate train and val\n",
    "    for batch in val_loader: #TODO: this won't work when I take lower batch sizes\n",
    "        input_ids_val = batch['input_ids']\n",
    "        attention_mask_val = batch['attention_mask']\n",
    "        labels_val = batch['labels']\n",
    "        # move the inputs to GPU\n",
    "        input_ids_val = input_ids_val.to('cuda')\n",
    "        attention_mask_val = attention_mask_val.to('cuda')\n",
    "        labels_val = labels_val.to('cuda')\n",
    "        # concatenate train and val\n",
    "    input_ids = torch.cat((input_ids_train, input_ids_val), axis=0)\n",
    "    attention_mask = torch.cat((attention_mask_train, attention_mask_val), axis=0)\n",
    "    labels = torch.cat((labels_train, labels_val), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    return model, input_ids, attention_mask, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 800, Val size: 200\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Epoch 1 - Training loss: 0.6252211928367615, Training accuracy: 0.655\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 1 - Validation loss: 0.5349120497703552, Validation accuracy: 0.75\n",
      "Validation loss decreased from inf to 0.5349120497703552\n",
      "Epoch 2 - Training loss: 0.6445856690406799, Training accuracy: 0.6425\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 2 - Validation loss: 0.525595486164093, Validation accuracy: 0.735\n",
      "Validation loss decreased from 0.5349120497703552 to 0.525595486164093\n",
      "Epoch 3 - Training loss: 0.5289170742034912, Training accuracy: 0.7075\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 3 - Validation loss: 0.5299437642097473, Validation accuracy: 0.725\n",
      "Early stopping counter: 1\n",
      "Epoch 4 - Training loss: 0.5535533428192139, Training accuracy: 0.7\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 4 - Validation loss: 0.5458489060401917, Validation accuracy: 0.735\n",
      "Early stopping counter: 2\n",
      "Epoch 5 - Training loss: 0.4328780770301819, Training accuracy: 0.775\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 5 - Validation loss: 0.589766263961792, Validation accuracy: 0.725\n",
      "Early stopping counter: 3\n",
      "Epoch 6 - Training loss: 0.4016801714897156, Training accuracy: 0.8075\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 6 - Validation loss: 0.667161762714386, Validation accuracy: 0.73\n",
      "Early stopping counter: 4\n",
      "Epoch 7 - Training loss: 0.3583846986293793, Training accuracy: 0.83\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 7 - Validation loss: 0.7777472734451294, Validation accuracy: 0.725\n",
      "Early stopping counter: 5\n",
      "Early stopping at epoch 7\n",
      "Finished training\n",
      "Evaluating model\n",
      "Train size: 1000, Val size: 4000\n",
      "Test loss: 0.4821208715438843, Test accuracy: 0.76675\n",
      "Train size: 800, Val size: 200\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Epoch 1 - Training loss: 0.6055419445037842, Training accuracy: 0.69\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 1 - Validation loss: 0.5259921550750732, Validation accuracy: 0.72\n",
      "Validation loss decreased from inf to 0.5259921550750732\n",
      "Epoch 2 - Training loss: 0.6238153576850891, Training accuracy: 0.6325\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 2 - Validation loss: 0.5396792888641357, Validation accuracy: 0.705\n",
      "Early stopping counter: 1\n",
      "Epoch 3 - Training loss: 0.4731139838695526, Training accuracy: 0.77\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 3 - Validation loss: 0.5616037249565125, Validation accuracy: 0.705\n",
      "Early stopping counter: 2\n",
      "Epoch 4 - Training loss: 0.47600695490837097, Training accuracy: 0.765\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 4 - Validation loss: 0.5912875533103943, Validation accuracy: 0.695\n",
      "Early stopping counter: 3\n",
      "Epoch 5 - Training loss: 0.4453023672103882, Training accuracy: 0.785\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 5 - Validation loss: 0.6328817009925842, Validation accuracy: 0.69\n",
      "Early stopping counter: 4\n",
      "Epoch 6 - Training loss: 0.36002877354621887, Training accuracy: 0.85\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 6 - Validation loss: 0.6936302185058594, Validation accuracy: 0.685\n",
      "Early stopping counter: 5\n",
      "Early stopping at epoch 6\n",
      "Finished training\n",
      "Evaluating model\n",
      "Train size: 1000, Val size: 4000\n",
      "Test loss: 0.5113580226898193, Test accuracy: 0.743\n",
      "Train size: 800, Val size: 200\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Epoch 1 - Training loss: 0.5995259881019592, Training accuracy: 0.6625\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 1 - Validation loss: 0.503872811794281, Validation accuracy: 0.73\n",
      "Validation loss decreased from inf to 0.503872811794281\n",
      "Epoch 2 - Training loss: 0.5838581323623657, Training accuracy: 0.69\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 2 - Validation loss: 0.4919623136520386, Validation accuracy: 0.765\n",
      "Validation loss decreased from 0.503872811794281 to 0.4919623136520386\n",
      "Epoch 3 - Training loss: 0.4624585211277008, Training accuracy: 0.7775\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 3 - Validation loss: 0.5050823092460632, Validation accuracy: 0.77\n",
      "Early stopping counter: 1\n",
      "Epoch 4 - Training loss: 0.4332180321216583, Training accuracy: 0.78\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 4 - Validation loss: 0.534695029258728, Validation accuracy: 0.76\n",
      "Early stopping counter: 2\n",
      "Epoch 5 - Training loss: 0.39656227827072144, Training accuracy: 0.8025\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 5 - Validation loss: 0.5679565668106079, Validation accuracy: 0.765\n",
      "Early stopping counter: 3\n",
      "Epoch 6 - Training loss: 0.34143301844596863, Training accuracy: 0.8375\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 6 - Validation loss: 0.6241733431816101, Validation accuracy: 0.75\n",
      "Early stopping counter: 4\n",
      "Epoch 7 - Training loss: 0.3402060568332672, Training accuracy: 0.8475\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 7 - Validation loss: 0.7112306952476501, Validation accuracy: 0.745\n",
      "Early stopping counter: 5\n",
      "Early stopping at epoch 7\n",
      "Finished training\n",
      "Evaluating model\n",
      "Train size: 1000, Val size: 4000\n",
      "Test loss: 0.5017060041427612, Test accuracy: 0.75425\n",
      "Train size: 800, Val size: 200\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Epoch 1 - Training loss: 0.568367600440979, Training accuracy: 0.7275\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 1 - Validation loss: 0.5064492225646973, Validation accuracy: 0.7\n",
      "Validation loss decreased from inf to 0.5064492225646973\n",
      "Epoch 2 - Training loss: 0.5827009677886963, Training accuracy: 0.69\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 2 - Validation loss: 0.49896836280822754, Validation accuracy: 0.77\n",
      "Validation loss decreased from 0.5064492225646973 to 0.49896836280822754\n",
      "Epoch 3 - Training loss: 0.46727144718170166, Training accuracy: 0.785\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 3 - Validation loss: 0.4992581903934479, Validation accuracy: 0.75\n",
      "Early stopping counter: 1\n",
      "Epoch 4 - Training loss: 0.413630872964859, Training accuracy: 0.8375\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 4 - Validation loss: 0.5000810027122498, Validation accuracy: 0.745\n",
      "Early stopping counter: 2\n",
      "Epoch 5 - Training loss: 0.3850637674331665, Training accuracy: 0.84\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 5 - Validation loss: 0.5089320540428162, Validation accuracy: 0.76\n",
      "Early stopping counter: 3\n",
      "Epoch 6 - Training loss: 0.3889537453651428, Training accuracy: 0.83\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 6 - Validation loss: 0.5414719581604004, Validation accuracy: 0.75\n",
      "Early stopping counter: 4\n",
      "Epoch 7 - Training loss: 0.34900611639022827, Training accuracy: 0.8375\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 7 - Validation loss: 0.5876765251159668, Validation accuracy: 0.75\n",
      "Early stopping counter: 5\n",
      "Early stopping at epoch 7\n",
      "Finished training\n",
      "Evaluating model\n",
      "Train size: 1000, Val size: 4000\n",
      "Test loss: 0.5154245495796204, Test accuracy: 0.74525\n",
      "Train size: 800, Val size: 200\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Epoch 1 - Training loss: 0.5907705426216125, Training accuracy: 0.675\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 1 - Validation loss: 0.577597439289093, Validation accuracy: 0.705\n",
      "Validation loss decreased from inf to 0.577597439289093\n",
      "Epoch 2 - Training loss: 0.578744113445282, Training accuracy: 0.715\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 2 - Validation loss: 0.564344048500061, Validation accuracy: 0.7\n",
      "Validation loss decreased from 0.577597439289093 to 0.564344048500061\n",
      "Epoch 3 - Training loss: 0.49544915556907654, Training accuracy: 0.7375\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 3 - Validation loss: 0.5654272437095642, Validation accuracy: 0.7\n",
      "Early stopping counter: 1\n",
      "Epoch 4 - Training loss: 0.4550226926803589, Training accuracy: 0.7925\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 4 - Validation loss: 0.5820538401603699, Validation accuracy: 0.685\n",
      "Early stopping counter: 2\n",
      "Epoch 5 - Training loss: 0.38423070311546326, Training accuracy: 0.82\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 5 - Validation loss: 0.6027799844741821, Validation accuracy: 0.68\n",
      "Early stopping counter: 3\n",
      "Epoch 6 - Training loss: 0.4352457821369171, Training accuracy: 0.805\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 6 - Validation loss: 0.6437990665435791, Validation accuracy: 0.685\n",
      "Early stopping counter: 4\n",
      "Epoch 7 - Training loss: 0.3590050935745239, Training accuracy: 0.8425\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Epoch 7 - Validation loss: 0.710062563419342, Validation accuracy: 0.68\n",
      "Early stopping counter: 5\n",
      "Early stopping at epoch 7\n",
      "Finished training\n",
      "Evaluating model\n",
      "Train size: 1000, Val size: 4000\n",
      "Test loss: 0.49344152212142944, Test accuracy: 0.75025\n"
     ]
    }
   ],
   "source": [
    "from src.utils import FixedSizeSplit\n",
    "cv = FixedSizeSplit(n_splits=5, n_train=1000, n_test=4000)\n",
    "transformer_name = \"distilroberta-base\"\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)\n",
    "texts = X.tolist()\n",
    "all_encoding = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = {k: v[train_index] for k, v in all_encoding.items()}, {k: v[test_index] for k, v in all_encoding.items()}\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #model, input_ids_train, attention_mask_train, labels_train = train_model(X_train, y_train, transformer_name=transformer_name)\n",
    "    model, input_ids_train, attention_mask_train, labels_train = train_model(X_train, y_train, transformer_name=transformer_name)\n",
    "    print(\"Finished training\")\n",
    "    # Evaluate on test set\n",
    "    # create a test dataset\n",
    "    \n",
    "\n",
    "    test_dataset = CustomDataset(X_test, torch.tensor(y_test).float().reshape(-1, 1))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    test_loss, test_accuracy = evaluate_model(test_loader, model, input_ids_train, attention_mask_train, labels_train)\n",
    "    print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    del input_ids_train, attention_mask_train, labels_train, model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76675, 0.743, 0.75425, 0.74525, 0.75025]\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "spotify",
           "GradientBoostingClassifier",
           "PCA_10",
           "lm__all-MiniLM-L12-v2",
           0.7431
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "PCA_10",
           "lm__whaleloops/phrase-bert",
           0.7453
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "PCA_30",
           "lm__all-MiniLM-L12-v2",
           0.73865
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "PCA_30",
           "lm__whaleloops/phrase-bert",
           0.7461
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "subset_10",
           "lm__all-MiniLM-L12-v2",
           0.61425
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "subset_10",
           "lm__whaleloops/phrase-bert",
           0.6688000000000001
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "subset_30",
           "lm__all-MiniLM-L12-v2",
           0.655
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "subset_30",
           "lm__whaleloops/phrase-bert",
           0.7321500000000001
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "subset_biggest_10",
           "lm__all-MiniLM-L12-v2",
           0.55565
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "subset_biggest_10",
           "lm__whaleloops/phrase-bert",
           0.52425
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "subset_biggest_30",
           "lm__all-MiniLM-L12-v2",
           0.5365
          ],
          [
           "spotify",
           "GradientBoostingClassifier",
           "subset_biggest_30",
           "lm__whaleloops/phrase-bert",
           0.5946
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "dataset: %{customdata[0]}<br>model: %{customdata[1]}<br>dim_reduction: %{customdata[2]}<br>encoding: %{customdata[3]}<br>accuracy: %{customdata[4]}",
         "legendgroup": "GradientBoostingClassifier",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#636efa"
         },
         "name": "GradientBoostingClassifier",
         "offsetgroup": "GradientBoostingClassifier",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": true,
         "type": "box",
         "x": [
          0.7431,
          0.7453,
          0.73865,
          0.7461,
          0.61425,
          0.6688000000000001,
          0.655,
          0.7321500000000001,
          0.55565,
          0.52425,
          0.5365,
          0.5946
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "spotify",
           "LogisticRegression",
           "PCA_10",
           "lm__all-MiniLM-L12-v2",
           0.7454500000000001
          ],
          [
           "spotify",
           "LogisticRegression",
           "PCA_10",
           "lm__whaleloops/phrase-bert",
           0.7595500000000001
          ],
          [
           "spotify",
           "LogisticRegression",
           "PCA_30",
           "lm__all-MiniLM-L12-v2",
           0.7509
          ],
          [
           "spotify",
           "LogisticRegression",
           "PCA_30",
           "lm__whaleloops/phrase-bert",
           0.75485
          ],
          [
           "spotify",
           "LogisticRegression",
           "passthrough",
           "lm__all-MiniLM-L12-v2",
           0.75295
          ],
          [
           "spotify",
           "LogisticRegression",
           "passthrough",
           "lm__whaleloops/phrase-bert",
           0.7227
          ],
          [
           "spotify",
           "LogisticRegression",
           "passthrough",
           "skrub__minhash_10",
           0.53965
          ],
          [
           "spotify",
           "LogisticRegression",
           "passthrough",
           "skrub__minhash_30",
           0.5486
          ],
          [
           "spotify",
           "LogisticRegression",
           "subset_10",
           "lm__all-MiniLM-L12-v2",
           0.6256
          ],
          [
           "spotify",
           "LogisticRegression",
           "subset_10",
           "lm__whaleloops/phrase-bert",
           0.6698999999999999
          ],
          [
           "spotify",
           "LogisticRegression",
           "subset_30",
           "lm__all-MiniLM-L12-v2",
           0.66955
          ],
          [
           "spotify",
           "LogisticRegression",
           "subset_30",
           "lm__whaleloops/phrase-bert",
           0.7398
          ],
          [
           "spotify",
           "LogisticRegression",
           "subset_biggest_10",
           "lm__all-MiniLM-L12-v2",
           0.5663
          ],
          [
           "spotify",
           "LogisticRegression",
           "subset_biggest_10",
           "lm__whaleloops/phrase-bert",
           0.5548
          ],
          [
           "spotify",
           "LogisticRegression",
           "subset_biggest_30",
           "lm__all-MiniLM-L12-v2",
           0.5433
          ],
          [
           "spotify",
           "LogisticRegression",
           "subset_biggest_30",
           "lm__whaleloops/phrase-bert",
           0.5227
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "dataset: %{customdata[0]}<br>model: %{customdata[1]}<br>dim_reduction: %{customdata[2]}<br>encoding: %{customdata[3]}<br>accuracy: %{customdata[4]}",
         "legendgroup": "LogisticRegression",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#EF553B"
         },
         "name": "LogisticRegression",
         "offsetgroup": "LogisticRegression",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": true,
         "type": "box",
         "x": [
          0.7454500000000001,
          0.7595500000000001,
          0.7509,
          0.75485,
          0.75295,
          0.7227,
          0.53965,
          0.5486,
          0.6256,
          0.6698999999999999,
          0.66955,
          0.7398,
          0.5663,
          0.5548,
          0.5433,
          0.5227
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "spotify",
           "TabPFNClassifier",
           "PCA_10",
           "lm__all-MiniLM-L12-v2",
           0.7495
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "PCA_10",
           "lm__whaleloops/phrase-bert",
           0.7617499999999999
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "PCA_30",
           "lm__all-MiniLM-L12-v2",
           0.75505
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "PCA_30",
           "lm__whaleloops/phrase-bert",
           0.7641
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "subset_10",
           "lm__all-MiniLM-L12-v2",
           0.6306
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "subset_10",
           "lm__whaleloops/phrase-bert",
           0.69505
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "subset_30",
           "lm__all-MiniLM-L12-v2",
           0.6799999999999999
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "subset_30",
           "lm__whaleloops/phrase-bert",
           0.75295
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "subset_biggest_10",
           "lm__all-MiniLM-L12-v2",
           0.5375
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "subset_biggest_10",
           "lm__whaleloops/phrase-bert",
           0.5462999999999999
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "subset_biggest_30",
           "lm__all-MiniLM-L12-v2",
           0.5254000000000001
          ],
          [
           "spotify",
           "TabPFNClassifier",
           "subset_biggest_30",
           "lm__whaleloops/phrase-bert",
           0.5295
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "dataset: %{customdata[0]}<br>model: %{customdata[1]}<br>dim_reduction: %{customdata[2]}<br>encoding: %{customdata[3]}<br>accuracy: %{customdata[4]}",
         "legendgroup": "TabPFNClassifier",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#00cc96"
         },
         "name": "TabPFNClassifier",
         "offsetgroup": "TabPFNClassifier",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": true,
         "type": "box",
         "x": [
          0.7495,
          0.7617499999999999,
          0.75505,
          0.7641,
          0.6306,
          0.69505,
          0.6799999999999999,
          0.75295,
          0.5375,
          0.5462999999999999,
          0.5254000000000001,
          0.5295
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "spotify",
           "bert",
           "none",
           "lm__all-MiniLM-L12-v2",
           0.7519
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "dataset: %{customdata[0]}<br>model: %{customdata[1]}<br>dim_reduction: %{customdata[2]}<br>encoding: %{customdata[3]}<br>accuracy: %{customdata[4]}",
         "legendgroup": "bert",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#ab63fa"
         },
         "name": "bert",
         "offsetgroup": "bert",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": true,
         "type": "box",
         "x": [
          0.7519
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "height": 600,
        "legend": {
         "title": {
          "text": "Model"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Swarm Plot of Model Accuracies Across Datasets"
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Dataset"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"76b5d550-8300-427b-9800-656655f5102e\" class=\"plotly-graph-div\" style=\"height:600px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"76b5d550-8300-427b-9800-656655f5102e\")) {                    Plotly.newPlot(                        \"76b5d550-8300-427b-9800-656655f5102e\",                        [{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"dataset: %{customdata[0]}\\u003cbr\\u003emodel: %{customdata[1]}\\u003cbr\\u003edim_reduction: %{customdata[2]}\\u003cbr\\u003eencoding: %{customdata[3]}\\u003cbr\\u003eaccuracy: %{customdata[4]}\",\"legendgroup\":\"GradientBoostingClassifier\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#636efa\"},\"name\":\"GradientBoostingClassifier\",\"offsetgroup\":\"GradientBoostingClassifier\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":true,\"x\":[0.7431,0.7453,0.73865,0.7461,0.61425,0.6688000000000001,0.655,0.7321500000000001,0.55565,0.52425,0.5365,0.5946],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\",\"customdata\":[[\"spotify\",\"GradientBoostingClassifier\",\"PCA_10\",\"lm__all-MiniLM-L12-v2\",0.7431],[\"spotify\",\"GradientBoostingClassifier\",\"PCA_10\",\"lm__whaleloops\\u002fphrase-bert\",0.7453],[\"spotify\",\"GradientBoostingClassifier\",\"PCA_30\",\"lm__all-MiniLM-L12-v2\",0.73865],[\"spotify\",\"GradientBoostingClassifier\",\"PCA_30\",\"lm__whaleloops\\u002fphrase-bert\",0.7461],[\"spotify\",\"GradientBoostingClassifier\",\"subset_10\",\"lm__all-MiniLM-L12-v2\",0.61425],[\"spotify\",\"GradientBoostingClassifier\",\"subset_10\",\"lm__whaleloops\\u002fphrase-bert\",0.6688000000000001],[\"spotify\",\"GradientBoostingClassifier\",\"subset_30\",\"lm__all-MiniLM-L12-v2\",0.655],[\"spotify\",\"GradientBoostingClassifier\",\"subset_30\",\"lm__whaleloops\\u002fphrase-bert\",0.7321500000000001],[\"spotify\",\"GradientBoostingClassifier\",\"subset_biggest_10\",\"lm__all-MiniLM-L12-v2\",0.55565],[\"spotify\",\"GradientBoostingClassifier\",\"subset_biggest_10\",\"lm__whaleloops\\u002fphrase-bert\",0.52425],[\"spotify\",\"GradientBoostingClassifier\",\"subset_biggest_30\",\"lm__all-MiniLM-L12-v2\",0.5365],[\"spotify\",\"GradientBoostingClassifier\",\"subset_biggest_30\",\"lm__whaleloops\\u002fphrase-bert\",0.5946]]},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"dataset: %{customdata[0]}\\u003cbr\\u003emodel: %{customdata[1]}\\u003cbr\\u003edim_reduction: %{customdata[2]}\\u003cbr\\u003eencoding: %{customdata[3]}\\u003cbr\\u003eaccuracy: %{customdata[4]}\",\"legendgroup\":\"LogisticRegression\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#EF553B\"},\"name\":\"LogisticRegression\",\"offsetgroup\":\"LogisticRegression\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":true,\"x\":[0.7454500000000001,0.7595500000000001,0.7509,0.75485,0.75295,0.7227,0.53965,0.5486,0.6256,0.6698999999999999,0.66955,0.7398,0.5663,0.5548,0.5433,0.5227],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\",\"customdata\":[[\"spotify\",\"LogisticRegression\",\"PCA_10\",\"lm__all-MiniLM-L12-v2\",0.7454500000000001],[\"spotify\",\"LogisticRegression\",\"PCA_10\",\"lm__whaleloops\\u002fphrase-bert\",0.7595500000000001],[\"spotify\",\"LogisticRegression\",\"PCA_30\",\"lm__all-MiniLM-L12-v2\",0.7509],[\"spotify\",\"LogisticRegression\",\"PCA_30\",\"lm__whaleloops\\u002fphrase-bert\",0.75485],[\"spotify\",\"LogisticRegression\",\"passthrough\",\"lm__all-MiniLM-L12-v2\",0.75295],[\"spotify\",\"LogisticRegression\",\"passthrough\",\"lm__whaleloops\\u002fphrase-bert\",0.7227],[\"spotify\",\"LogisticRegression\",\"passthrough\",\"skrub__minhash_10\",0.53965],[\"spotify\",\"LogisticRegression\",\"passthrough\",\"skrub__minhash_30\",0.5486],[\"spotify\",\"LogisticRegression\",\"subset_10\",\"lm__all-MiniLM-L12-v2\",0.6256],[\"spotify\",\"LogisticRegression\",\"subset_10\",\"lm__whaleloops\\u002fphrase-bert\",0.6698999999999999],[\"spotify\",\"LogisticRegression\",\"subset_30\",\"lm__all-MiniLM-L12-v2\",0.66955],[\"spotify\",\"LogisticRegression\",\"subset_30\",\"lm__whaleloops\\u002fphrase-bert\",0.7398],[\"spotify\",\"LogisticRegression\",\"subset_biggest_10\",\"lm__all-MiniLM-L12-v2\",0.5663],[\"spotify\",\"LogisticRegression\",\"subset_biggest_10\",\"lm__whaleloops\\u002fphrase-bert\",0.5548],[\"spotify\",\"LogisticRegression\",\"subset_biggest_30\",\"lm__all-MiniLM-L12-v2\",0.5433],[\"spotify\",\"LogisticRegression\",\"subset_biggest_30\",\"lm__whaleloops\\u002fphrase-bert\",0.5227]]},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"dataset: %{customdata[0]}\\u003cbr\\u003emodel: %{customdata[1]}\\u003cbr\\u003edim_reduction: %{customdata[2]}\\u003cbr\\u003eencoding: %{customdata[3]}\\u003cbr\\u003eaccuracy: %{customdata[4]}\",\"legendgroup\":\"TabPFNClassifier\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#00cc96\"},\"name\":\"TabPFNClassifier\",\"offsetgroup\":\"TabPFNClassifier\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":true,\"x\":[0.7495,0.7617499999999999,0.75505,0.7641,0.6306,0.69505,0.6799999999999999,0.75295,0.5375,0.5462999999999999,0.5254000000000001,0.5295],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\",\"customdata\":[[\"spotify\",\"TabPFNClassifier\",\"PCA_10\",\"lm__all-MiniLM-L12-v2\",0.7495],[\"spotify\",\"TabPFNClassifier\",\"PCA_10\",\"lm__whaleloops\\u002fphrase-bert\",0.7617499999999999],[\"spotify\",\"TabPFNClassifier\",\"PCA_30\",\"lm__all-MiniLM-L12-v2\",0.75505],[\"spotify\",\"TabPFNClassifier\",\"PCA_30\",\"lm__whaleloops\\u002fphrase-bert\",0.7641],[\"spotify\",\"TabPFNClassifier\",\"subset_10\",\"lm__all-MiniLM-L12-v2\",0.6306],[\"spotify\",\"TabPFNClassifier\",\"subset_10\",\"lm__whaleloops\\u002fphrase-bert\",0.69505],[\"spotify\",\"TabPFNClassifier\",\"subset_30\",\"lm__all-MiniLM-L12-v2\",0.6799999999999999],[\"spotify\",\"TabPFNClassifier\",\"subset_30\",\"lm__whaleloops\\u002fphrase-bert\",0.75295],[\"spotify\",\"TabPFNClassifier\",\"subset_biggest_10\",\"lm__all-MiniLM-L12-v2\",0.5375],[\"spotify\",\"TabPFNClassifier\",\"subset_biggest_10\",\"lm__whaleloops\\u002fphrase-bert\",0.5462999999999999],[\"spotify\",\"TabPFNClassifier\",\"subset_biggest_30\",\"lm__all-MiniLM-L12-v2\",0.5254000000000001],[\"spotify\",\"TabPFNClassifier\",\"subset_biggest_30\",\"lm__whaleloops\\u002fphrase-bert\",0.5295]]},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"dataset: %{customdata[0]}\\u003cbr\\u003emodel: %{customdata[1]}\\u003cbr\\u003edim_reduction: %{customdata[2]}\\u003cbr\\u003eencoding: %{customdata[3]}\\u003cbr\\u003eaccuracy: %{customdata[4]}\",\"legendgroup\":\"bert\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#ab63fa\"},\"name\":\"bert\",\"offsetgroup\":\"bert\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":true,\"x\":[0.7519],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[\"spotify\"],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\",\"customdata\":[[\"spotify\",\"bert\",\"none\",\"lm__all-MiniLM-L12-v2\",0.7519]]}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Accuracy\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dataset\"}},\"legend\":{\"title\":{\"text\":\"Model\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Swarm Plot of Model Accuracies Across Datasets\"},\"boxmode\":\"group\",\"height\":600,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('76b5d550-8300-427b-9800-656655f5102e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "df = pd.read_csv(\"../results/results.csv\")\n",
    "df = df[df[\"dataset\"] == \"spotify\"]\n",
    "# add new rows with test accuracies\n",
    "new_rows = {\"dataset\": [\"spotify\"] * 5, \"model\": [\"bert\"] * 5, \"dim_reduction\": [\"none\"] * 5, \"encoding\": [\"lm__all-MiniLM-L12-v2\"] * 5, \"accuracy\": test_accuracies}\n",
    "df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "melted_results = df.groupby(['dataset', 'model', 'dim_reduction', 'encoding']).mean().reset_index()\n",
    "#melted_results = results.explode('accuracy')\n",
    "#melted_results['accuracy'] = melted_results['accuracy'].astype(float)\n",
    "#melted_results = melted_results[melted_results['encoding'] == 'lm__all-MiniLM-L12-v2']\n",
    "\n",
    "\n",
    "# Creating the swarmplot\n",
    "# plt.figure(figsize=(15, 20))\n",
    "# sns.swarmplot(data=melted_results, x='accuracy', y='dataset', hue='model', dodge=True)\n",
    "# plt.title('Swarm Plot of Model Accuracies Across Datasets')\n",
    "# plt.xlabel('Accuracy')\n",
    "# plt.ylabel('Dataset')\n",
    "# plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.show()\n",
    "# Create the plot\n",
    "fig = px.strip(\n",
    "    data_frame=melted_results,\n",
    "    x=\"accuracy\",\n",
    "    y=\"dataset\",\n",
    "    color=\"model\",\n",
    "    #color=\"dim_reduction\",\n",
    "    title=\"Swarm Plot of Model Accuracies Across Datasets\",\n",
    "    labels={\"accuracy\": \"Accuracy\", \"dataset\": \"Dataset\", \"model\": \"Model\"},\n",
    "    height=600,\n",
    "    width=900,\n",
    ")\n",
    "\n",
    "# Update hover information for each trace (grouped by 'color' or 'model' in this case)\n",
    "for i, trace in enumerate(fig.data):\n",
    "    subset_df = melted_results[melted_results['model'] == trace.name]\n",
    "    hover_template = \"<br>\".join([f\"{col}: %{{customdata[{i}]}}\" for i, col in enumerate(subset_df.columns)])\n",
    "    trace.customdata = subset_df.values\n",
    "    trace.hovertemplate = hover_template\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Epoch 1 - Training loss: 0.6134790182113647, Training accuracy: 0.6433333333333333\n",
      "Validation loss decreased from inf to 0.5111220479011536\n",
      "Epoch 1 - Validation loss: 0.5111220479011536\n",
      "Epoch 1 - Validation accuracy: 0.732\n",
      "Epoch 2 - Training loss: 0.6185330748558044, Training accuracy: 0.6633333333333333\n",
      "Validation loss decreased from 0.5111220479011536 to 0.5057411789894104\n",
      "Epoch 2 - Validation loss: 0.5057411789894104\n",
      "Epoch 2 - Validation accuracy: 0.728\n",
      "Epoch 3 - Training loss: 0.48609843850135803, Training accuracy: 0.7466666666666667\n",
      "Early stopping counter: 1\n",
      "Epoch 3 - Validation loss: 0.5087280869483948\n",
      "Epoch 3 - Validation accuracy: 0.735\n",
      "Epoch 4 - Training loss: 0.483054518699646, Training accuracy: 0.7733333333333333\n",
      "Early stopping counter: 2\n",
      "Epoch 4 - Validation loss: 0.520322859287262\n",
      "Epoch 4 - Validation accuracy: 0.74\n",
      "Epoch 5 - Training loss: 0.4642616808414459, Training accuracy: 0.78\n",
      "Early stopping counter: 3\n",
      "Epoch 5 - Validation loss: 0.5428574085235596\n",
      "Epoch 5 - Validation accuracy: 0.735\n",
      "Epoch 6 - Training loss: 0.45587217807769775, Training accuracy: 0.7833333333333333\n",
      "Early stopping counter: 4\n",
      "Epoch 6 - Validation loss: 0.5706436634063721\n",
      "Epoch 6 - Validation accuracy: 0.73\n",
      "Epoch 7 - Training loss: 0.3596241772174835, Training accuracy: 0.8733333333333333\n",
      "Early stopping counter: 5\n",
      "Early stopping at epoch 7\n",
      "Test loss: 0.4904043674468994\n",
      "Test accuracy: 0.7538157894736842\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.utils import preprocess_input\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "\n",
    "# Your text data and labels (replace these with your actual data and labels)\n",
    "# Your text data and labels (replace these with your actual data and labels)\n",
    "#texts = X_original[column_to_consider].tolist()\n",
    "texts = X.tolist()\n",
    "#labels = (y_original > np.median(y_original)).tolist()\n",
    "#labels = y_original.tolist()\n",
    "labels = y.tolist()\n",
    "\n",
    "# Tokenize the text data\n",
    "#encoding = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Create a custom dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "#dataset = CustomDataset(encoding, torch.tensor(labels).float().reshape(-1, 1))\n",
    "#print(f\"Dataset size: {len(dataset)}\")\n",
    "train_size = 700\n",
    "val_size = 1000 #TODO\n",
    "\n",
    "all_encoding = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "encoding_train = {k: v[:train_size] for k, v in all_encoding.items()}\n",
    "encoding_val = {k: v[train_size:train_size+val_size] for k, v in all_encoding.items()}\n",
    "encoding_test = {k: v[train_size+val_size:] for k, v in all_encoding.items()}\n",
    "train_dataset = CustomDataset(encoding_train, torch.tensor(labels).float().reshape(-1, 1)[:train_size])\n",
    "val_dataset = CustomDataset(encoding_val, torch.tensor(labels).float().reshape(-1, 1)[train_size:train_size+val_size])\n",
    "test_dataset = CustomDataset(encoding_test, torch.tensor(labels).float().reshape(-1, 1)[train_size+val_size:])\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "#model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model = BertAndTabPFN(preprocess_before_tabpfn=True, linear_translator=False).to('cuda')\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "es_patience = 5\n",
    "es_tolerance = 1e-4\n",
    "es_counter = 0\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "best_val_loss = np.inf\n",
    "for epoch in range(num_epochs):\n",
    "    if es_counter >= es_patience:\n",
    "        break\n",
    "    ###########\n",
    "    # Train loop\n",
    "    model.train()\n",
    "    train_preds, train_labels, train_losses = [], [], []\n",
    "    for batch in train_loader:\n",
    "        input_ids_train = batch['input_ids']\n",
    "        attention_mask_train = batch['attention_mask']\n",
    "        labels_train = batch['labels']\n",
    "        # move the inputs to GPU\n",
    "        input_ids_train = input_ids_train.to('cuda')\n",
    "        attention_mask_train = attention_mask_train.to('cuda')\n",
    "        labels_train = labels_train.to('cuda')\n",
    "        single_eval_pos = 400\n",
    "        output = model(input_ids_train, attention_mask=attention_mask_train, y=labels_train, single_eval_pos=single_eval_pos).squeeze()\n",
    "        loss = nn.CrossEntropyLoss()(output, labels_train[single_eval_pos:].long().reshape(-1))\n",
    "        if epoch > 0:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # compute train accuracy\n",
    "        preds = torch.argmax(output, axis=-1).cpu().detach().numpy()\n",
    "        #train_accuracy = accuracy_score(labels_train[single_eval_pos:].cpu().detach().numpy().reshape(-1), preds)\n",
    "        #print(f\"Epoch {epoch + 1} - Training loss: {loss}, Training accuracy: {train_accuracy}\")\n",
    "        train_losses.append(loss.cpu().item())\n",
    "        train_preds.append(preds)\n",
    "        train_labels.append(labels_train[single_eval_pos:].cpu().detach().numpy().reshape(-1))\n",
    "    train_preds = np.concatenate(train_preds)\n",
    "    train_labels = np.concatenate(train_labels)\n",
    "    train_losses = np.mean(train_losses)\n",
    "    print(f\"Epoch {epoch + 1} - Training loss: {train_losses}, Training accuracy: {accuracy_score(train_labels, train_preds)}\")\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_preds, val_labels, val_losses = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader: #TODO: remove the useless for loop\n",
    "            input_ids_val = batch['input_ids']\n",
    "            attention_mask_val = batch['attention_mask']\n",
    "            labels_val = batch['labels']\n",
    "            # move the inputs to GPU\n",
    "            input_ids_val = input_ids_val.to('cuda')\n",
    "            attention_mask_val = attention_mask_val.to('cuda')\n",
    "            labels_val = labels_val.to('cuda')\n",
    "            # concatenate train and val\n",
    "            #TODO: make sure this is correct, no leak etc\n",
    "            # maybe safer to create a TabPFNClassifier with the same parameters as the one in BertAndTabPFN\n",
    "            input_ids = torch.cat((input_ids_train, input_ids_val), axis=0)\n",
    "            attention_mask = torch.cat((attention_mask_train, attention_mask_val), axis=0)\n",
    "            labels = torch.cat((labels_train, labels_val), axis=0)\n",
    "            single_eval_pos = train_size\n",
    "            output = model(input_ids, attention_mask=attention_mask, y=labels, single_eval_pos=single_eval_pos).squeeze()\n",
    "            val_loss = nn.CrossEntropyLoss()(output, labels[single_eval_pos:].long().reshape(-1))\n",
    "            if val_loss < best_val_loss - es_tolerance:\n",
    "                print(f\"Validation loss decreased from {best_val_loss} to {val_loss}\")\n",
    "                best_val_loss = val_loss\n",
    "                # save the model\n",
    "                torch.save(model.state_dict(), \"checkpoints/model.pt\")\n",
    "                # save input_ids_train, attention_mask_train, labels_train\n",
    "                torch.save(input_ids_train, \"checkpoints/input_ids_train.pt\")\n",
    "                torch.save(attention_mask_train, \"checkpoints/attention_mask_train.pt\")\n",
    "                torch.save(labels_train, \"checkpoints/labels_train.pt\")\n",
    "            else:\n",
    "                es_counter += 1\n",
    "                print(f\"Early stopping counter: {es_counter}\")\n",
    "                if es_counter >= es_patience:\n",
    "                    print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                    break\n",
    "\n",
    "\n",
    "            val_losses.append(val_loss.cpu())\n",
    "            preds = torch.argmax(output, axis=-1).cpu().detach().numpy()\n",
    "            val_preds.append(preds)\n",
    "            val_labels.append(labels[single_eval_pos:].cpu().detach().numpy().reshape(-1))\n",
    "        else:\n",
    "            val_preds = np.concatenate(val_preds)\n",
    "            val_labels = np.concatenate(val_labels)\n",
    "            val_losses = np.mean(val_losses)\n",
    "            print(f\"Epoch {epoch + 1} - Validation loss: {val_losses}\")\n",
    "            # Compute accuracy\n",
    "            val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "            print(f\"Epoch {epoch + 1} - Validation accuracy: {val_accuracy}\")\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"checkpoints/model.pt\"))\n",
    "input_ids_train = torch.load(\"checkpoints/input_ids_train.pt\")\n",
    "attention_mask_train = torch.load(\"checkpoints/attention_mask_train.pt\")\n",
    "labels_train = torch.load(\"checkpoints/labels_train.pt\")\n",
    "\n",
    "# Test loop\n",
    "model.eval()\n",
    "test_preds, test_labels, test_losses = [], [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids_test = batch['input_ids']\n",
    "        attention_mask_test = batch['attention_mask']\n",
    "        labels_test = batch['labels']\n",
    "        # move the inputs to GPU\n",
    "        input_ids_test = input_ids_test.to('cuda')\n",
    "        attention_mask_test = attention_mask_test.to('cuda')\n",
    "        labels_test = labels_test.to('cuda')\n",
    "        # concatenate train and val\n",
    "        #TODO put this back\n",
    "        #input_ids = torch.cat((input_ids_train, input_ids_test), axis=0)\n",
    "        #attention_mask = torch.cat((attention_mask_train, attention_mask_test), axis=0)\n",
    "        #labels = torch.cat((labels_train, labels_test), axis=0)\n",
    "        single_eval_pos = train_size\n",
    "\n",
    "        output = model(input_ids_test, attention_mask=attention_mask_test, y=labels_test, single_eval_pos=single_eval_pos).squeeze()\n",
    "        test_loss = nn.CrossEntropyLoss()(output, labels_test[single_eval_pos:].long().reshape(-1))\n",
    "        test_losses.append(test_loss.cpu())\n",
    "        preds = torch.argmax(output, axis=-1).cpu().detach().numpy()\n",
    "        test_preds.append(preds)\n",
    "        test_labels.append(labels_test[single_eval_pos:].cpu().detach().numpy().reshape(-1))\n",
    "\n",
    "test_preds = np.concatenate(test_preds)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "test_losses = np.mean(test_losses)\n",
    "print(f\"Test loss: {test_losses}\")\n",
    "print(f\"Test accuracy: {accuracy_score(test_labels, test_preds)}\")\n",
    "\n",
    "# Save the model\n",
    "# model.save_pretrained(\"./fine_tuned_bert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(input_ids_train, \"checkpoints/input_ids_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "checkpoints  launch.ipynb  results2.csv  test  tests.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
