{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loading import load_data\n",
    "from skrub import MinHashEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from src.utils import FeaturesExtractor, FixedSizeSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/lgrinszt/lm_tab/scripts\n"
     ]
    }
   ],
   "source": [
    "%cd lm_tab/scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/lgrinszt/lm_tab/scripts\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import BertAndTabPFN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.utils import preprocess_input\n",
    "from icecream import ic\n",
    "\n",
    "# Create a custom dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx],\n",
    "            'tabular_data': self.encodings['tabular_data'][idx] if 'tabular_data' in self.encodings.keys() else None\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "# copied from huggingface\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import math\n",
    "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5, last_epoch=-1):\n",
    "    \"\"\" Create a schedule with a learning rate that decreases following the\n",
    "    values of the cosine function between 0 and `pi * cycles` after a warmup\n",
    "    period during which it increases linearly between 0 and 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
    "\n",
    "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
    "\n",
    "def evaluate_model(dataloader, model, input_ids_train, attention_mask_train, labels_train, tabular_data_train):\n",
    "    print(\"Evaluating model\")\n",
    "    model.eval()\n",
    "    val_preds, val_labels, val_losses = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader: #TODO: remove the useless for loop\n",
    "            input_ids_val = batch['input_ids']\n",
    "            attention_mask_val = batch['attention_mask']\n",
    "            labels_val = batch['labels']\n",
    "            if \"tabular_data\" in batch.keys():\n",
    "                tabular_data_val = batch[\"tabular_data\"].to('cuda')\n",
    "            else:\n",
    "                tabular_data_val = None\n",
    "            # move the inputs to GPU\n",
    "            input_ids_val = input_ids_val.to('cuda')\n",
    "            attention_mask_val = attention_mask_val.to('cuda')\n",
    "            labels_val = labels_val.to('cuda')\n",
    "            # concatenate train and val\n",
    "            #TODO: make sure this is correct, no leak etc\n",
    "            # maybe safer to create a TabPFNClassifier with the same parameters as the one in BertAndTabPFN\n",
    "            input_ids = torch.cat((input_ids_train, input_ids_val), axis=0)\n",
    "            attention_mask = torch.cat((attention_mask_train, attention_mask_val), axis=0)\n",
    "            labels = torch.cat((labels_train, labels_val), axis=0)\n",
    "            if tabular_data_train is not None:\n",
    "                tabular_data = torch.cat((tabular_data_train, tabular_data_val), axis=0)\n",
    "            else:\n",
    "                tabular_data = None\n",
    "            single_eval_pos = len(input_ids_train)\n",
    "            if single_eval_pos > 1024:\n",
    "                print(\"WARNING: single_eval_pos > 1024\")\n",
    "            print(f\"Train size: {len(input_ids_train)}, Val size: {len(input_ids_val)}\")\n",
    "            print(f\"Single eval pos for evaluation: {single_eval_pos}\")\n",
    "            output = model(input_ids, attention_mask=attention_mask, y=labels, tabular_data=tabular_data, single_eval_pos=single_eval_pos).squeeze()\n",
    "            val_loss = nn.CrossEntropyLoss()(output, labels[single_eval_pos:].long().reshape(-1))\n",
    "            val_losses.append(val_loss.cpu())\n",
    "            preds = torch.argmax(output, axis=-1).cpu().detach().numpy()\n",
    "            val_preds.append(preds)\n",
    "            val_labels.append(labels[single_eval_pos:].cpu().detach().numpy().reshape(-1))\n",
    "        val_preds = np.concatenate(val_preds)\n",
    "        val_labels = np.concatenate(val_labels)\n",
    "        loss = np.mean(val_losses)\n",
    "        accuracy = accuracy_score(val_labels, val_preds)\n",
    "    \n",
    "    # try with tabpfn classifier to see if there is a difference\n",
    "    # tabfn_input_train = model(input_ids_train, attention_mask=attention_mask_train, y=labels_train, single_eval_pos=single_eval_pos, return_tabpfn_input=True).cpu().detach().numpy()\n",
    "    # clf = model.raw_tabpfn\n",
    "    # clf.fit(tabfn_input_train, labels_train.cpu().detach().numpy())\n",
    "    # tabfn_input_val = model(input_ids_val, attention_mask=attention_mask_val, y=labels_val, single_eval_pos=single_eval_pos, return_tabpfn_input=True).cpu().detach().numpy()\n",
    "    # val_preds = clf.predict(tabfn_input_val)\n",
    "    # val_labels = labels_val.cpu().detach().numpy()\n",
    "    # accuracy_clf = accuracy_score(val_labels, val_preds)\n",
    "    # print(f\"Accuracy with tabpfn classifier: {accuracy_clf}\")\n",
    "    # print(f\"Accuracy raw: {accuracy}\")\n",
    "    # # move back to cuda\n",
    "\n",
    "        \n",
    "    model.train()\n",
    "    return loss, accuracy\n",
    "    \n",
    "\n",
    "def train_model(X_enc_dic, y, n_epochs=20, single_eval_pos_train=500, lr=1e-4,\n",
    "                prop_train=0.8):\n",
    "\n",
    "    train_size = int(prop_train * len(X_enc_dic[\"input_ids\"]))\n",
    "    val_size = len(X_enc_dic[\"input_ids\"]) - train_size\n",
    "    print(f\"Train size: {train_size}, Val size: {val_size} for training\")\n",
    "    X_train, X_val = {k: v[:train_size] for k, v in X_enc_dic.items()}, {k: v[train_size:] for k, v in X_enc_dic.items()}\n",
    "    y_train, y_val = y[:train_size], y[train_size:]\n",
    "    train_dataset = CustomDataset(X_train, torch.tensor(y_train).float().reshape(-1, 1))\n",
    "    val_dataset = CustomDataset(X_val, torch.tensor(y_val).float().reshape(-1, 1))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)#TODO\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    #model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "    model = BertAndTabPFN(**kwargs).to('cuda')\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    es_patience = 4\n",
    "    es_tolerance = 1e-4\n",
    "    es_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = n_epochs\n",
    "    best_val_loss = np.inf\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    for epoch in range(max(num_epochs, 1)): # if num_epochs is 0, we still want to evaluate the model once, but we don't train it\n",
    "        print(\"Epoch\", epoch + 1)\n",
    "        if es_counter >= es_patience:\n",
    "            break\n",
    "        ###########\n",
    "        # Train loop\n",
    "        model.train()\n",
    "        train_preds, train_labels, train_losses_epoch = [], [], []\n",
    "        for batch in train_loader:\n",
    "            input_ids_train = batch['input_ids']\n",
    "            attention_mask_train = batch['attention_mask']\n",
    "            labels_train = batch['labels']\n",
    "            if \"tabular_data\" in batch:\n",
    "                tabular_data_train = batch[\"tabular_data\"].to('cuda')\n",
    "                assert tabular_data_train is not None\n",
    "            else:\n",
    "                tabular_data_train = None\n",
    "            # move the inputs to GPU\n",
    "            input_ids_train = input_ids_train.to('cuda')\n",
    "            attention_mask_train = attention_mask_train.to('cuda')\n",
    "            labels_train = labels_train.to('cuda')\n",
    "            single_eval_pos = single_eval_pos_train\n",
    "            print(\"training, single_eval_pos\", single_eval_pos)\n",
    "            # print(f\"Tabular data: {tabular_data_train}\")\n",
    "            # print)\n",
    "            output = model(input_ids_train, attention_mask=attention_mask_train, y=labels_train, single_eval_pos=single_eval_pos,\n",
    "                           tabular_data=tabular_data_train).squeeze()\n",
    "            loss = nn.CrossEntropyLoss()(output, labels_train[single_eval_pos:].long().reshape(-1))\n",
    "            if num_epochs >= 1:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            # compute train accuracy\n",
    "            preds = torch.argmax(output, axis=-1).cpu().detach().numpy()\n",
    "            train_losses_epoch.append(loss.cpu().item())\n",
    "            train_preds.append(preds)\n",
    "            train_labels.append(labels_train[single_eval_pos:].cpu().detach().numpy().reshape(-1))\n",
    "        train_preds = np.concatenate(train_preds)\n",
    "        train_labels = np.concatenate(train_labels)\n",
    "        train_loss_epoch = np.mean(train_losses_epoch)\n",
    "        train_losses.append(train_loss_epoch)\n",
    "        train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        print(f\"Epoch {epoch + 1} - Training loss: {train_loss_epoch}, Training accuracy: {train_accuracy}\")\n",
    "\n",
    "        # Validation loop\n",
    "        val_loss, val_accuracy = evaluate_model(val_loader, model, input_ids_train, attention_mask_train, labels_train, tabular_data_train)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        print(f\"Epoch {epoch + 1} - Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n",
    "        if val_loss < best_val_loss - es_tolerance:\n",
    "            print(f\"Validation loss decreased from {best_val_loss} to {val_loss}\")\n",
    "            best_val_loss = val_loss\n",
    "            # save the model\n",
    "            print(\"Saving model\")\n",
    "            torch.save(model.state_dict(), \"checkpoints/model.pt\") #TODO: make sure no overlap with other models\n",
    "            # save input_ids_train, attention_mask_train, labels_train\n",
    "            #torch.save(input_ids_train, \"checkpoints/input_ids_train.pt\")\n",
    "            #torch.save(attention_mask_train, \"checkpoints/attention_mask_train.pt\")\n",
    "            #torch.save(labels_train, \"checkpoints/labels_train.pt\")\n",
    "        else:\n",
    "            es_counter += 1\n",
    "            print(f\"Early stopping counter: {es_counter}\")\n",
    "            if es_counter >= es_patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "    # Load the best model\n",
    "    time.sleep(3) # otherwise I have some bugs if the model has just been saved\n",
    "    model.load_state_dict(torch.load(\"checkpoints/model.pt\"))\n",
    "    #input_ids_train = torch.load(\"checkpoints/input_ids_train.pt\")\n",
    "    #attention_mask_train = torch.load(\"checkpoints/attention_mask_train.pt\")\n",
    "    #labels_train = torch.load(\"checkpoints/labels_train.pt\")\n",
    "    # concatenate train and val\n",
    "    for batch in val_loader: #TODO: this won't work when I take lower batch sizes\n",
    "        input_ids_val = batch['input_ids']\n",
    "        attention_mask_val = batch['attention_mask']\n",
    "        labels_val = batch['labels']\n",
    "        if \"tabular_data\" in X_val:\n",
    "            tabular_data_val = X_val[\"tabular_data\"].to('cuda')\n",
    "        else:\n",
    "            tabular_data_val = None\n",
    "        # move the inputs to GPU\n",
    "        input_ids_val = input_ids_val.to('cuda')\n",
    "        attention_mask_val = attention_mask_val.to('cuda')\n",
    "        labels_val = labels_val.to('cuda')\n",
    "        # concatenate train and val\n",
    "    input_ids = torch.cat((input_ids_train, input_ids_val), axis=0)\n",
    "    attention_mask = torch.cat((attention_mask_train, attention_mask_val), axis=0)\n",
    "    labels = torch.cat((labels_train, labels_val), axis=0)\n",
    "    tabular_data = torch.cat((tabular_data_train, tabular_data_val), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    return model, input_ids, attention_mask, labels, tabular_data, train_losses, train_accuracies, val_losses, val_accuracies #TODO use a dictionary instead of returning all these variables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO create a function to run with submitit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the right max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer_name = \"distilroberta-base\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(transformer_name)\n",
    "# #datasets = [\"journal_jcr_cls\", \"movies\", \"michelin\", \"spotify\", \"employee_salary\", \"museums\", \"fifa_footballplayers_22\", \"jp_anime\"]\n",
    "# datasets = [\"journal_jcr_cls\", \"spotify\", \"museums\", \"employee_salary\"]\n",
    "\n",
    "# for dataset in datasets:\n",
    "#     test_losses = []\n",
    "#     test_accuracies = []\n",
    "#     train_losses_setting = [] # for this config\n",
    "#     train_accuracies_setting = []\n",
    "#     val_losses_setting = []\n",
    "#     val_accuracies_setting = []\n",
    "\n",
    "#     X_text, X_rest, y = load_data(dataset, max_rows=10000, include_all_columns=True)\n",
    "#     # label encoding\n",
    "#     #y = y.astype('category').cat.codes\n",
    "#     y = y.astype(np.int64)\n",
    "#     texts = X_text.tolist()\n",
    "#     all_encoding = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#     print(all_encoding[\"input_ids\"].shape)\n",
    "#     # print the non-padded length median and quantiles\n",
    "#     non_padded_lengths = np.sum(all_encoding[\"attention_mask\"].numpy(), axis=1)\n",
    "#     max_length = np.quantile(non_padded_lengths, 0.95)\n",
    "#     all_encoding = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=int(max_length), return_tensors=\"pt\")\n",
    "#     print(all_encoding[\"input_ids\"].shape)\n",
    "#     print(\"-------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original task: classification for journal_jcr_cls\n",
      "Removed 0 columns with missing values on 4 columns\n",
      "Removed 485 rows with missing values on 5710 rows\n",
      "Removed 485 rows with missing values on 5710 rows\n",
      "Removed 0 columns with missing values on 4 columns\n",
      "New shape: (5225, 4)\n",
      "X_text shape: (5225,), X_rest shape: (5225, 4), y shape: (5225,)\n",
      "Train size: 800, Val size: 200 for training\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Epoch 1\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 1 - Training loss: 0.669478178024292, Training accuracy: 0.595\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 1 - Validation loss: 0.7029833197593689, Validation accuracy: 0.53\n",
      "Validation loss decreased from inf to 0.7029833197593689\n",
      "Saving model\n",
      "Epoch 2\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 2 - Training loss: 0.6821632981300354, Training accuracy: 0.5875\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 2 - Validation loss: 0.7005521655082703, Validation accuracy: 0.525\n",
      "Validation loss decreased from 0.7029833197593689 to 0.7005521655082703\n",
      "Saving model\n",
      "Epoch 3\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 3 - Training loss: 0.6949430108070374, Training accuracy: 0.5575\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 3 - Validation loss: 0.6991515159606934, Validation accuracy: 0.53\n",
      "Validation loss decreased from 0.7005521655082703 to 0.6991515159606934\n",
      "Saving model\n",
      "Epoch 4\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 4 - Training loss: 0.6705494523048401, Training accuracy: 0.5975\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 4 - Validation loss: 0.7041577696800232, Validation accuracy: 0.53\n",
      "Early stopping counter: 1\n",
      "Epoch 5\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 5 - Training loss: 0.6823627948760986, Training accuracy: 0.57\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 5 - Validation loss: 0.6994835734367371, Validation accuracy: 0.53\n",
      "Early stopping counter: 2\n",
      "Epoch 6\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 6 - Training loss: 0.6769378185272217, Training accuracy: 0.5775\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 6 - Validation loss: 0.7008272409439087, Validation accuracy: 0.53\n",
      "Early stopping counter: 3\n",
      "Epoch 7\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 7 - Training loss: 0.6716291904449463, Training accuracy: 0.6075\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 7 - Validation loss: 0.7000173926353455, Validation accuracy: 0.53\n",
      "Early stopping counter: 4\n",
      "Early stopping at epoch 7\n",
      "Finished training\n",
      "Evaluating model\n",
      "Train size: 1000, Val size: 2000\n",
      "Single eval pos for evaluation: 1000\n",
      "Using additional tabular data of shape torch.Size([3000, 31])\n",
      "Test loss: 0.6678182482719421, Test accuracy: 0.5895\n",
      "Train size: 800, Val size: 200 for training\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Epoch 1\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 1 - Training loss: 0.6791308522224426, Training accuracy: 0.565\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 1 - Validation loss: 0.6533328890800476, Validation accuracy: 0.615\n",
      "Validation loss decreased from inf to 0.6533328890800476\n",
      "Saving model\n",
      "Epoch 2\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 2 - Training loss: 0.6847386956214905, Training accuracy: 0.5525\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 2 - Validation loss: 0.6573619842529297, Validation accuracy: 0.605\n",
      "Early stopping counter: 1\n",
      "Epoch 3\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 3 - Training loss: 0.6879527568817139, Training accuracy: 0.5375\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 3 - Validation loss: 0.6555756330490112, Validation accuracy: 0.61\n",
      "Early stopping counter: 2\n",
      "Epoch 4\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 4 - Training loss: 0.6849011778831482, Training accuracy: 0.57\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 4 - Validation loss: 0.6570117473602295, Validation accuracy: 0.6\n",
      "Early stopping counter: 3\n",
      "Epoch 5\n",
      "training, single_eval_pos 400\n",
      "Using additional tabular data of shape torch.Size([800, 31])\n",
      "Epoch 5 - Training loss: 0.6831811666488647, Training accuracy: 0.56\n",
      "Evaluating model\n",
      "Train size: 800, Val size: 200\n",
      "Single eval pos for evaluation: 800\n",
      "Using additional tabular data of shape torch.Size([1000, 31])\n",
      "Epoch 5 - Validation loss: 0.6581456065177917, Validation accuracy: 0.59\n",
      "Early stopping counter: 4\n",
      "Early stopping at epoch 5\n",
      "Finished training\n",
      "Evaluating model\n",
      "Train size: 1000, Val size: 2000\n",
      "Single eval pos for evaluation: 1000\n",
      "Using additional tabular data of shape torch.Size([3000, 31])\n",
      "Test loss: 0.6579213738441467, Test accuracy: 0.612\n",
      "Train size: 800, Val size: 200 for training\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Epoch 1\n",
      "training, single_eval_pos 400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/leo/VSCProjects/lm_tab/scripts/launch copy.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m X_test \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mX_enc_test, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtabular_data\u001b[39m\u001b[39m\"\u001b[39m: X_rest_test}}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m#model, input_ids_train, attention_mask_train, labels_train = train_model(X_train, y_train, transformer_name=transformer_name)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m model, input_ids_train, attention_mask_train, labels_train, tabular_data_train, train_losses, train_accuracies, val_losses, val_accuracies \u001b[39m=\u001b[39m train_model(X_train, y_train, n_epochs\u001b[39m=\u001b[39;49mn_epochs, lr\u001b[39m=\u001b[39;49mlr, single_eval_pos_train\u001b[39m=\u001b[39;49msingle_eval_pos_train, prop_train\u001b[39m=\u001b[39;49mprop_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m                                                                                                                                                          n_epoch_per_gradient\u001b[39m=\u001b[39;49mn_epoch_per_gradient,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m                                                                                                                                                         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_config)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m all_train_losses\u001b[39m.\u001b[39mappend(train_losses)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m all_val_losses\u001b[39m.\u001b[39mappend(val_losses)\n",
      "\u001b[1;32m/Users/leo/VSCProjects/lm_tab/scripts/launch copy.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtraining, single_eval_pos\u001b[39m\u001b[39m\"\u001b[39m, single_eval_pos)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m \u001b[39m# print(f\"Tabular data: {tabular_data_train}\")\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m \u001b[39m# print)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m output \u001b[39m=\u001b[39m model(input_ids_train, attention_mask\u001b[39m=\u001b[39;49mattention_mask_train, y\u001b[39m=\u001b[39;49mlabels_train, single_eval_pos\u001b[39m=\u001b[39;49msingle_eval_pos,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m                tabular_data\u001b[39m=\u001b[39;49mtabular_data_train)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()(output, labels_train[single_eval_pos:]\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/leo/VSCProjects/lm_tab/scripts/launch%20copy.ipynb#X15sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m \u001b[39mif\u001b[39;00m num_epochs \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m: \u001b[39m# to be able to use num_epochs=0\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/lgrinszt/micromamba/envs/dpo/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/lgrinszt/lm_tab/src/models.py:86\u001b[0m, in \u001b[0;36mBertAndTabPFN.forward\u001b[0;34m(self, input_ids, attention_mask, y, tabular_data, single_eval_pos, return_tabpfn_input)\u001b[0m\n\u001b[1;32m     84\u001b[0m     tabpfn_input \u001b[39m=\u001b[39m bert_embeddings[:, :\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_tabpfn]\n\u001b[1;32m     85\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimension_reduction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpca\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 86\u001b[0m     tabpfn_input \u001b[39m=\u001b[39m torchPCA(bert_embeddings, n_components\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdim_tabpfn)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m return_tabpfn_input:\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m tabpfn_input\n",
      "File \u001b[0;32m/scratch/lgrinszt/lm_tab/src/models.py:21\u001b[0m, in \u001b[0;36mtorchPCA\u001b[0;34m(X, n_components)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtorchPCA\u001b[39m(X, n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[1;32m     20\u001b[0m     X \u001b[39m=\u001b[39m X \u001b[39m-\u001b[39m X\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m     U, S, Vt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49msvd(X, full_matrices\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     22\u001b[0m     \u001b[39m#return U[:, :n_components] * S[:n_components]\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m X \u001b[39m@\u001b[39m Vt\u001b[39m.\u001b[39mt()[:, :n_components]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.utils import FixedSizeSplit\n",
    "import pandas as pd\n",
    "from skrub import TableVectorizer\n",
    "from sklearn.preprocessing import OrdinalEncoder, PowerTransformer\n",
    "cv = FixedSizeSplit(n_splits=5, n_train=1000, n_test=2000, random_state=42)\n",
    "transformer_name = \"sentence-transformers/all-distilroberta-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)\n",
    "#datasets = [\"journal_jcr_cls\", \"movies\", \"michelin\", \"spotify\", \"employee_salary\", \"museums\", \"fifa_footballplayers_22\", \"jp_anime\"]\n",
    "datasets = [\"journal_jcr_cls\", \"spotify\", \"museums\", \"employee_salary\"]\n",
    "results = pd.DataFrame(columns=[\"dataset\", \"encoding\", \"dim_reduction\", \"model\", \"accuracy\", \"numerical_transformer\", \"lr\", \"single_eval_pos_train\", \"dim_tabpfn\", \"n_epochs\"])\n",
    "#results = pd.read_csv(\"results_training_with_numerics_new.csv\")\n",
    "all_train_losses = []\n",
    "all_train_accuracies = []\n",
    "all_val_losses = []\n",
    "all_val_accuracies = []\n",
    "all_test_losses = []\n",
    "all_test_accuracies = []\n",
    "for numerical_transformer_name in [\"passthrough\"]:#, \"power_transformer\"]:\n",
    "    if numerical_transformer_name == \"passthrough\":\n",
    "        numerical_transformer = \"passthrough\"\n",
    "    elif numerical_transformer_name == \"power_transformer\":\n",
    "        numerical_transformer = PowerTransformer(standardize=True)\n",
    "\n",
    "    rest_trans = TableVectorizer(high_card_cat_transformer=MinHashEncoder(n_components=10),\n",
    "        low_card_cat_transformer=OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), #TODO: not sure about this\n",
    "        numerical_transformer=numerical_transformer,\n",
    "        cardinality_threshold=10)\n",
    "    for lr in [1e-5]:\n",
    "        for single_eval_pos_train in [400]:\n",
    "            for dim_tabpfn in [30]:\n",
    "                for n_epochs in [10, 0]:\n",
    "                    for disable_dropout in [False]:\n",
    "                        for dimension_reduction in [\"pca\"]:\n",
    "                            for embedding_strategy in [\"mean_pooling\"]:\n",
    "                                for n_epoch_per_gradient in [10, 3, 1]:\n",
    "                                    model_config = {\"transformer_name\": transformer_name, \"dim_tabpfn\": dim_tabpfn,\n",
    "                                                    \"disable_dropout\": disable_dropout, \"dimension_reduction\": dimension_reduction, \"embedding_strategy\": embedding_strategy,\n",
    "                                                    \"preprocess_before_tabpfn\": True, \"lora\": False, \"train_tabpfn\": False}\n",
    "                                    for prop_train in [0.8]:\n",
    "                                        for dataset in datasets:\n",
    "                                            test_losses = []\n",
    "                                            test_accuracies = []\n",
    "                                            train_losses_setting = [] # for this config\n",
    "                                            train_accuracies_setting = []\n",
    "                                            val_losses_setting = []\n",
    "                                            val_accuracies_setting = []\n",
    "                                            #TODO same tokenization than SentenceTransformer\n",
    "                                            X_text, X_rest, y = load_data(dataset, max_rows=10000, include_all_columns=True)\n",
    "                                            # label encoding\n",
    "                                            #y = y.astype('category').cat.codes\n",
    "                                            y = y.astype(np.int64)\n",
    "                                            texts = X_text.tolist()\n",
    "                                            all_encoding = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "                                            # print the non-padded length median and quantiles\n",
    "                                            non_padded_lengths = np.sum(all_encoding[\"attention_mask\"].numpy(), axis=1)\n",
    "                                            max_length = np.quantile(non_padded_lengths, 0.95)\n",
    "                                            all_encoding = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=int(max_length), return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "                                            for train_index, test_index in cv.split(X_rest, y):\n",
    "                                                X_enc_train, X_enc_test = {k: v[train_index] for k, v in all_encoding.items()}, {k: v[test_index] for k, v in all_encoding.items()}\n",
    "                                                y_train, y_test = y[train_index], y[test_index]\n",
    "                                                X_rest_train, X_rest_test = X_rest.iloc[train_index], X_rest.iloc[test_index]\n",
    "\n",
    "                                                # encode the rest\n",
    "                                                X_rest_train = rest_trans.fit_transform(X_rest_train)\n",
    "                                                X_rest_test = rest_trans.transform(X_rest_test)\n",
    "                                                # convert to tensors\n",
    "                                                X_rest_train = torch.tensor(X_rest_train).float()\n",
    "                                                X_rest_test = torch.tensor(X_rest_test).float()\n",
    "                                                # concatenate the two\n",
    "                                                X_train = {**X_enc_train, **{\"tabular_data\": X_rest_train}}\n",
    "                                                X_test = {**X_enc_test, **{\"tabular_data\": X_rest_test}}\n",
    "                                                #model, input_ids_train, attention_mask_train, labels_train = train_model(X_train, y_train, transformer_name=transformer_name)\n",
    "                                                model, input_ids_train, attention_mask_train, labels_train, tabular_data_train, train_losses, train_accuracies, val_losses, val_accuracies = train_model(X_train, y_train, n_epochs=n_epochs, lr=lr, single_eval_pos_train=single_eval_pos_train, prop_train=prop_train,\n",
    "                                                                                                                                                                                                         n_epoch_per_gradient=n_epoch_per_gradient,\n",
    "                                                                                                                                                                                                        **model_config)\n",
    "                                                all_train_losses.append(train_losses)\n",
    "                                                all_val_losses.append(val_losses)\n",
    "                                                all_train_accuracies.append(train_accuracies)\n",
    "                                                all_val_accuracies.append(val_accuracies)\n",
    "                                                train_losses_setting.append(train_losses)\n",
    "                                                train_accuracies_setting.append(train_accuracies)\n",
    "                                                val_losses_setting.append(val_losses)\n",
    "                                                val_accuracies_setting.append(val_accuracies)\n",
    "                                                print(\"Finished training\")\n",
    "                                                # Evaluate on test set\n",
    "                                                # create a test dataset\n",
    "                                                \n",
    "\n",
    "                                                test_dataset = CustomDataset(X_test, torch.tensor(y_test).float().reshape(-1, 1))\n",
    "                                                test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "                                                test_loss, test_accuracy = evaluate_model(test_loader, model, input_ids_train, attention_mask_train, labels_train, tabular_data_train)\n",
    "                                                print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n",
    "                                                test_losses.append(test_loss)\n",
    "                                                test_accuracies.append(test_accuracy)\n",
    "                                                del input_ids_train, attention_mask_train, labels_train, model, tabular_data_train\n",
    "                                                torch.cuda.empty_cache()\n",
    "                                            # print memory usage\n",
    "                                            #print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "                                            res = {\"dataset\": [dataset] * 5, \"encoding\": [f\"bert_{numerical_transformer_name}\"] * 5, \"model\": [f\"{transformer_name}_tabpfn_lora\"] * 5, \n",
    "                                                                                        \"numerical_transformer\": [numerical_transformer_name] * 5, \"lr\": [lr] * 5, \"single_eval_pos_train\": [single_eval_pos_train] * 5, \"n_epochs\": [n_epochs] * 5,\n",
    "                                                                                        \"n_epoch_per_gradient\": [n_epoch_per_gradient] * 5,\n",
    "                                                                                        \"prop_train\": [prop_train] * 5, \n",
    "                                                                                        \"train_loss\": train_losses_setting.copy(), \"train_accuracy\": train_accuracies_setting.copy(),\n",
    "                                                                                        \"val_loss\": val_losses_setting.copy(), \"val_accuracy\": val_accuracies_setting.copy(), \"test_loss\": test_losses.copy(),\n",
    "                                                                                        \"accuracy\": test_accuracies.copy()}\n",
    "                                            res.update(model_config)\n",
    "                                            results = pd.concat([results, pd.DataFrame(res)])\n",
    "                                            results.to_csv(\"results_training_with_numerics_epoch_per_gradient.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>encoding</th>\n",
       "      <th>dim_reduction</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>numerical_transformer</th>\n",
       "      <th>lr</th>\n",
       "      <th>single_eval_pos_train</th>\n",
       "      <th>dim_tabpfn</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>...</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>transformer_name</th>\n",
       "      <th>disable_dropout</th>\n",
       "      <th>dimension_reduction</th>\n",
       "      <th>embedding_strategy</th>\n",
       "      <th>preprocess_before_tabpfn</th>\n",
       "      <th>lora</th>\n",
       "      <th>train_tabpfn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>journal_jcr_cls</td>\n",
       "      <td>bert_passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1_tab...</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.69864976]</td>\n",
       "      <td>[0.535]</td>\n",
       "      <td>0.683756</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1</td>\n",
       "      <td>False</td>\n",
       "      <td>pca</td>\n",
       "      <td>mean_pooling</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>journal_jcr_cls</td>\n",
       "      <td>bert_passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1_tab...</td>\n",
       "      <td>0.5840</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.6631319]</td>\n",
       "      <td>[0.62]</td>\n",
       "      <td>0.669742</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1</td>\n",
       "      <td>False</td>\n",
       "      <td>pca</td>\n",
       "      <td>mean_pooling</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journal_jcr_cls</td>\n",
       "      <td>bert_passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1_tab...</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.65712875]</td>\n",
       "      <td>[0.635]</td>\n",
       "      <td>0.684241</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1</td>\n",
       "      <td>False</td>\n",
       "      <td>pca</td>\n",
       "      <td>mean_pooling</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journal_jcr_cls</td>\n",
       "      <td>bert_passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1_tab...</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.68104315]</td>\n",
       "      <td>[0.565]</td>\n",
       "      <td>0.674868</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1</td>\n",
       "      <td>False</td>\n",
       "      <td>pca</td>\n",
       "      <td>mean_pooling</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>journal_jcr_cls</td>\n",
       "      <td>bert_passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1_tab...</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.68454766]</td>\n",
       "      <td>[0.555]</td>\n",
       "      <td>0.678132</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1</td>\n",
       "      <td>False</td>\n",
       "      <td>pca</td>\n",
       "      <td>mean_pooling</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>employee_salary</td>\n",
       "      <td>bert_passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1_tab...</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>600</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.19602793, 0.19554706, 0.19674593, 0.1958671...</td>\n",
       "      <td>[0.905, 0.915, 0.915, 0.92, 0.92, 0.92]</td>\n",
       "      <td>0.212940</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1</td>\n",
       "      <td>True</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_pooling</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>employee_salary</td>\n",
       "      <td>bert_passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1_tab...</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>600</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.22276445, 0.22695594, 0.23255458, 0.2378468...</td>\n",
       "      <td>[0.91, 0.91, 0.915, 0.915, 0.92]</td>\n",
       "      <td>0.217309</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1</td>\n",
       "      <td>True</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_pooling</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>employee_salary</td>\n",
       "      <td>bert_passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1_tab...</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>600</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.20164019, 0.20460421, 0.20829621, 0.2096572...</td>\n",
       "      <td>[0.91, 0.9, 0.9, 0.9, 0.9]</td>\n",
       "      <td>0.199332</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1</td>\n",
       "      <td>True</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_pooling</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>employee_salary</td>\n",
       "      <td>bert_passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1_tab...</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>600</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.28902552, 0.288173, 0.28464746, 0.2795413, ...</td>\n",
       "      <td>[0.905, 0.9, 0.9, 0.91, 0.91, 0.925, 0.935, 0....</td>\n",
       "      <td>0.243185</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1</td>\n",
       "      <td>True</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_pooling</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>employee_salary</td>\n",
       "      <td>bert_passthrough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1_tab...</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>600</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.22749145, 0.22667094, 0.2257547, 0.22540618...</td>\n",
       "      <td>[0.9, 0.9, 0.895, 0.9, 0.905, 0.9, 0.905, 0.90...</td>\n",
       "      <td>0.230625</td>\n",
       "      <td>sentence-transformers/all-distilroberta-v1</td>\n",
       "      <td>True</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_pooling</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset          encoding  dim_reduction  \\\n",
       "0     journal_jcr_cls  bert_passthrough            NaN   \n",
       "1     journal_jcr_cls  bert_passthrough            NaN   \n",
       "2     journal_jcr_cls  bert_passthrough            NaN   \n",
       "3     journal_jcr_cls  bert_passthrough            NaN   \n",
       "4     journal_jcr_cls  bert_passthrough            NaN   \n",
       "...               ...               ...            ...   \n",
       "1435  employee_salary  bert_passthrough            NaN   \n",
       "1436  employee_salary  bert_passthrough            NaN   \n",
       "1437  employee_salary  bert_passthrough            NaN   \n",
       "1438  employee_salary  bert_passthrough            NaN   \n",
       "1439  employee_salary  bert_passthrough            NaN   \n",
       "\n",
       "                                                  model  accuracy  \\\n",
       "0     sentence-transformers/all-distilroberta-v1_tab...    0.5600   \n",
       "1     sentence-transformers/all-distilroberta-v1_tab...    0.5840   \n",
       "2     sentence-transformers/all-distilroberta-v1_tab...    0.5590   \n",
       "3     sentence-transformers/all-distilroberta-v1_tab...    0.5825   \n",
       "4     sentence-transformers/all-distilroberta-v1_tab...    0.5780   \n",
       "...                                                 ...       ...   \n",
       "1435  sentence-transformers/all-distilroberta-v1_tab...    0.9105   \n",
       "1436  sentence-transformers/all-distilroberta-v1_tab...    0.9045   \n",
       "1437  sentence-transformers/all-distilroberta-v1_tab...    0.9155   \n",
       "1438  sentence-transformers/all-distilroberta-v1_tab...    0.9065   \n",
       "1439  sentence-transformers/all-distilroberta-v1_tab...    0.9010   \n",
       "\n",
       "     numerical_transformer       lr  single_eval_pos_train  dim_tabpfn  \\\n",
       "0              passthrough  0.00001                    400          10   \n",
       "1              passthrough  0.00001                    400          10   \n",
       "2              passthrough  0.00001                    400          10   \n",
       "3              passthrough  0.00001                    400          10   \n",
       "4              passthrough  0.00001                    400          10   \n",
       "...                    ...      ...                    ...         ...   \n",
       "1435           passthrough  0.00001                    600          35   \n",
       "1436           passthrough  0.00001                    600          35   \n",
       "1437           passthrough  0.00001                    600          35   \n",
       "1438           passthrough  0.00001                    600          35   \n",
       "1439           passthrough  0.00001                    600          35   \n",
       "\n",
       "      n_epochs  ...                                           val_loss  \\\n",
       "0            0  ...                                       [0.69864976]   \n",
       "1            0  ...                                        [0.6631319]   \n",
       "2            0  ...                                       [0.65712875]   \n",
       "3            0  ...                                       [0.68104315]   \n",
       "4            0  ...                                       [0.68454766]   \n",
       "...        ...  ...                                                ...   \n",
       "1435        10  ...  [0.19602793, 0.19554706, 0.19674593, 0.1958671...   \n",
       "1436        10  ...  [0.22276445, 0.22695594, 0.23255458, 0.2378468...   \n",
       "1437        10  ...  [0.20164019, 0.20460421, 0.20829621, 0.2096572...   \n",
       "1438        10  ...  [0.28902552, 0.288173, 0.28464746, 0.2795413, ...   \n",
       "1439        10  ...  [0.22749145, 0.22667094, 0.2257547, 0.22540618...   \n",
       "\n",
       "                                           val_accuracy test_loss  \\\n",
       "0                                               [0.535]  0.683756   \n",
       "1                                                [0.62]  0.669742   \n",
       "2                                               [0.635]  0.684241   \n",
       "3                                               [0.565]  0.674868   \n",
       "4                                               [0.555]  0.678132   \n",
       "...                                                 ...       ...   \n",
       "1435            [0.905, 0.915, 0.915, 0.92, 0.92, 0.92]  0.212940   \n",
       "1436                   [0.91, 0.91, 0.915, 0.915, 0.92]  0.217309   \n",
       "1437                         [0.91, 0.9, 0.9, 0.9, 0.9]  0.199332   \n",
       "1438  [0.905, 0.9, 0.9, 0.91, 0.91, 0.925, 0.935, 0....  0.243185   \n",
       "1439  [0.9, 0.9, 0.895, 0.9, 0.905, 0.9, 0.905, 0.90...  0.230625   \n",
       "\n",
       "                                transformer_name disable_dropout  \\\n",
       "0     sentence-transformers/all-distilroberta-v1           False   \n",
       "1     sentence-transformers/all-distilroberta-v1           False   \n",
       "2     sentence-transformers/all-distilroberta-v1           False   \n",
       "3     sentence-transformers/all-distilroberta-v1           False   \n",
       "4     sentence-transformers/all-distilroberta-v1           False   \n",
       "...                                          ...             ...   \n",
       "1435  sentence-transformers/all-distilroberta-v1            True   \n",
       "1436  sentence-transformers/all-distilroberta-v1            True   \n",
       "1437  sentence-transformers/all-distilroberta-v1            True   \n",
       "1438  sentence-transformers/all-distilroberta-v1            True   \n",
       "1439  sentence-transformers/all-distilroberta-v1            True   \n",
       "\n",
       "      dimension_reduction embedding_strategy  preprocess_before_tabpfn   lora  \\\n",
       "0                     pca       mean_pooling                      True  False   \n",
       "1                     pca       mean_pooling                      True  False   \n",
       "2                     pca       mean_pooling                      True  False   \n",
       "3                     pca       mean_pooling                      True  False   \n",
       "4                     pca       mean_pooling                      True  False   \n",
       "...                   ...                ...                       ...    ...   \n",
       "1435               linear       mean_pooling                      True  False   \n",
       "1436               linear       mean_pooling                      True  False   \n",
       "1437               linear       mean_pooling                      True  False   \n",
       "1438               linear       mean_pooling                      True  False   \n",
       "1439               linear       mean_pooling                      True  False   \n",
       "\n",
       "     train_tabpfn  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  \n",
       "...           ...  \n",
       "1435        False  \n",
       "1436        False  \n",
       "1437        False  \n",
       "1438        False  \n",
       "1439        False  \n",
       "\n",
       "[1440 rows x 23 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = pd.read_csv(\"results_training_with_numerics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "results_to_plot = results[results[\"n_epochs\"] == 10]\n",
    "results_to_plot = results_to_plot[results_to_plot[\"dataset\"] == \"museums\"]\n",
    "for i in range(len(results_to_plot)):\n",
    "    plt.plot(eval(results_to_plot.iloc[i][\"train_loss\"]), color=\"red\")\n",
    "    plt.plot(eval(results_to_plot.iloc[i][\"val_loss\"]), color=\"blue\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "linear"
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "n_epochs=%{customdata[6]}<br>dimension_reduction=%{customdata[9]}<br>Accuracy=%{x}<br>Dataset=%{y}<br>Model=%{customdata[0]}<br>encoding=%{customdata[1]}<br>numerical_transformer=%{customdata[2]}<br>lr=%{customdata[3]}<br>single_eval_pos_train=%{customdata[4]}<br>dim_tabpfn=%{customdata[5]}<br>prop_train=%{customdata[7]}<br>disable_dropout=%{customdata[8]}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#636efa"
         },
         "name": "0",
         "offsetgroup": "0",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": true,
         "type": "box",
         "x": [
          0.8805999999999999,
          0.8807,
          0.907,
          0.907,
          0.8836999999999999,
          0.8839,
          0.9057000000000001,
          0.9048999999999999,
          0.5621,
          0.5599000000000001,
          0.5700000000000001,
          0.5671999999999999,
          0.5591,
          0.5589000000000001,
          0.5722,
          0.5671,
          0.648,
          0.6418,
          0.6431,
          0.6372,
          0.6481,
          0.6439,
          0.6363,
          0.6428,
          0.7687999999999999,
          0.7662,
          0.787,
          0.7838,
          0.7653,
          0.7639,
          0.7812,
          0.7846
         ],
         "x0": " ",
         "xaxis": "x3",
         "y": [
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y3"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "pca"
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "n_epochs=%{customdata[6]}<br>dimension_reduction=%{customdata[9]}<br>Accuracy=%{x}<br>Dataset=%{y}<br>Model=%{customdata[0]}<br>encoding=%{customdata[1]}<br>numerical_transformer=%{customdata[2]}<br>lr=%{customdata[3]}<br>single_eval_pos_train=%{customdata[4]}<br>dim_tabpfn=%{customdata[5]}<br>prop_train=%{customdata[7]}<br>disable_dropout=%{customdata[8]}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#636efa"
         },
         "name": "0",
         "offsetgroup": "0",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": false,
         "type": "box",
         "x": [
          0.8940999999999999,
          0.8949,
          0.9141,
          0.9132999999999999,
          0.8934,
          0.8932,
          0.9146000000000001,
          0.9129999999999999,
          0.5727,
          0.5746,
          0.5948,
          0.5949,
          0.5742,
          0.5742,
          0.5934,
          0.5926,
          0.6504,
          0.65,
          0.6418,
          0.643,
          0.6505,
          0.6492,
          0.6424,
          0.642,
          0.8295999999999999,
          0.8305999999999999,
          0.8231999999999999,
          0.8244,
          0.8294,
          0.8304,
          0.8252,
          0.8246
         ],
         "x0": " ",
         "xaxis": "x2",
         "y": [
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y2"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           0,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           0,
           0.8,
           true,
           "subset"
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "n_epochs=%{customdata[6]}<br>dimension_reduction=%{customdata[9]}<br>Accuracy=%{x}<br>Dataset=%{y}<br>Model=%{customdata[0]}<br>encoding=%{customdata[1]}<br>numerical_transformer=%{customdata[2]}<br>lr=%{customdata[3]}<br>single_eval_pos_train=%{customdata[4]}<br>dim_tabpfn=%{customdata[5]}<br>prop_train=%{customdata[7]}<br>disable_dropout=%{customdata[8]}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#636efa"
         },
         "name": "0",
         "offsetgroup": "0",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": false,
         "type": "box",
         "x": [
          0.8901,
          0.8901,
          0.9093,
          0.9093,
          0.8901,
          0.8901,
          0.9093,
          0.9093,
          0.5582,
          0.5582,
          0.5626,
          0.5626,
          0.5582,
          0.5582,
          0.5626,
          0.5626,
          0.6375,
          0.6375,
          0.6346,
          0.6346,
          0.6375,
          0.6375,
          0.6345,
          0.6345,
          0.7615999999999999,
          0.7615999999999999,
          0.787,
          0.7870999999999999,
          0.7615999999999999,
          0.7615999999999999,
          0.7870999999999999,
          0.7870999999999999
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "linear"
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "n_epochs=%{customdata[6]}<br>dimension_reduction=%{customdata[9]}<br>Accuracy=%{x}<br>Dataset=%{y}<br>Model=%{customdata[0]}<br>encoding=%{customdata[1]}<br>numerical_transformer=%{customdata[2]}<br>lr=%{customdata[3]}<br>single_eval_pos_train=%{customdata[4]}<br>dim_tabpfn=%{customdata[5]}<br>prop_train=%{customdata[7]}<br>disable_dropout=%{customdata[8]}<extra></extra>",
         "legendgroup": "1",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#EF553B"
         },
         "name": "1",
         "offsetgroup": "1",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": true,
         "type": "box",
         "x": [
          0.8874000000000001,
          0.8903000000000001,
          0.908,
          0.9099999999999999,
          0.8825,
          0.8846,
          0.9117000000000001,
          0.9080999999999999,
          0.5573,
          0.5605,
          0.5767,
          0.5740000000000001,
          0.5561,
          0.5649,
          0.5726,
          0.5677,
          0.6416000000000001,
          0.6420999999999999,
          0.641,
          0.642,
          0.6344000000000001,
          0.6407,
          0.6359999999999999,
          0.6405000000000001,
          0.7745,
          0.7724,
          0.7932,
          0.796,
          0.7662,
          0.7713,
          0.7863,
          0.7802
         ],
         "x0": " ",
         "xaxis": "x3",
         "y": [
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y3"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "pca"
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "n_epochs=%{customdata[6]}<br>dimension_reduction=%{customdata[9]}<br>Accuracy=%{x}<br>Dataset=%{y}<br>Model=%{customdata[0]}<br>encoding=%{customdata[1]}<br>numerical_transformer=%{customdata[2]}<br>lr=%{customdata[3]}<br>single_eval_pos_train=%{customdata[4]}<br>dim_tabpfn=%{customdata[5]}<br>prop_train=%{customdata[7]}<br>disable_dropout=%{customdata[8]}<extra></extra>",
         "legendgroup": "1",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#EF553B"
         },
         "name": "1",
         "offsetgroup": "1",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": false,
         "type": "box",
         "x": [
          0.8946,
          0.8962,
          0.9138,
          0.9146000000000001,
          0.8932,
          0.8966999999999998,
          0.9136,
          0.9141999999999999,
          0.5765,
          0.5753,
          0.5944,
          0.5942999999999999,
          0.5745,
          0.5795,
          0.5947,
          0.5939,
          0.6515,
          0.6522,
          0.6435,
          0.6423,
          0.6533,
          0.6521,
          0.6429,
          0.6424,
          0.8302999999999999,
          0.8305,
          0.8257999999999999,
          0.8234999999999999,
          0.8303,
          0.8311999999999999,
          0.8242,
          0.8241999999999999
         ],
         "x0": " ",
         "xaxis": "x2",
         "y": [
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y2"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           1,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           1,
           0.8,
           true,
           "subset"
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "n_epochs=%{customdata[6]}<br>dimension_reduction=%{customdata[9]}<br>Accuracy=%{x}<br>Dataset=%{y}<br>Model=%{customdata[0]}<br>encoding=%{customdata[1]}<br>numerical_transformer=%{customdata[2]}<br>lr=%{customdata[3]}<br>single_eval_pos_train=%{customdata[4]}<br>dim_tabpfn=%{customdata[5]}<br>prop_train=%{customdata[7]}<br>disable_dropout=%{customdata[8]}<extra></extra>",
         "legendgroup": "1",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#EF553B"
         },
         "name": "1",
         "offsetgroup": "1",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": false,
         "type": "box",
         "x": [
          0.8919,
          0.8939999999999999,
          0.9096,
          0.9107,
          0.8916999999999999,
          0.8924,
          0.9086000000000001,
          0.9093,
          0.5574,
          0.5586,
          0.564,
          0.5654,
          0.5591,
          0.5586,
          0.5636,
          0.5650999999999999,
          0.6357999999999999,
          0.6355999999999999,
          0.6347,
          0.6332,
          0.6348,
          0.6345,
          0.6338999999999999,
          0.6362,
          0.7684,
          0.7683,
          0.79,
          0.7898,
          0.7689,
          0.7668999999999999,
          0.7911,
          0.7895
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "linear"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "linear"
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "n_epochs=%{customdata[6]}<br>dimension_reduction=%{customdata[9]}<br>Accuracy=%{x}<br>Dataset=%{y}<br>Model=%{customdata[0]}<br>encoding=%{customdata[1]}<br>numerical_transformer=%{customdata[2]}<br>lr=%{customdata[3]}<br>single_eval_pos_train=%{customdata[4]}<br>dim_tabpfn=%{customdata[5]}<br>prop_train=%{customdata[7]}<br>disable_dropout=%{customdata[8]}<extra></extra>",
         "legendgroup": "10",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#00cc96"
         },
         "name": "10",
         "offsetgroup": "10",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": true,
         "type": "box",
         "x": [
          0.9064,
          0.9019,
          0.9074,
          0.9088,
          0.9000999999999999,
          0.9006000000000001,
          0.908,
          0.9076000000000001,
          0.568,
          0.5705,
          0.5779,
          0.578,
          0.5740000000000001,
          0.5652,
          0.5730999999999999,
          0.5758,
          0.6452,
          0.6365000000000001,
          0.6359,
          0.6368,
          0.6453,
          0.6323,
          0.6407,
          0.6345000000000001,
          0.8,
          0.8023,
          0.8006,
          0.7978,
          0.7943,
          0.7985,
          0.7997,
          0.792
         ],
         "x0": " ",
         "xaxis": "x3",
         "y": [
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y3"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "pca"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "pca"
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "n_epochs=%{customdata[6]}<br>dimension_reduction=%{customdata[9]}<br>Accuracy=%{x}<br>Dataset=%{y}<br>Model=%{customdata[0]}<br>encoding=%{customdata[1]}<br>numerical_transformer=%{customdata[2]}<br>lr=%{customdata[3]}<br>single_eval_pos_train=%{customdata[4]}<br>dim_tabpfn=%{customdata[5]}<br>prop_train=%{customdata[7]}<br>disable_dropout=%{customdata[8]}<extra></extra>",
         "legendgroup": "10",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#00cc96"
         },
         "name": "10",
         "offsetgroup": "10",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": false,
         "type": "box",
         "x": [
          0.9071999999999999,
          0.9080999999999999,
          0.9144,
          0.9157,
          0.9010999999999999,
          0.9012,
          0.9148999999999999,
          0.9141,
          0.5825,
          0.5838,
          0.597,
          0.597,
          0.5824,
          0.5861000000000001,
          0.5944,
          0.5967,
          0.6565,
          0.6571,
          0.6463,
          0.6413,
          0.6529999999999999,
          0.6532,
          0.6436,
          0.6424,
          0.8308,
          0.8301000000000001,
          0.8237,
          0.8248,
          0.8311,
          0.8311999999999999,
          0.8236000000000001,
          0.8243
         ],
         "x0": " ",
         "xaxis": "x2",
         "y": [
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y2"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "customdata": [
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           10,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           400,
           35,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           10,
           10,
           0.8,
           true,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           false,
           "subset"
          ],
          [
           "sentence-transformers/all-distilroberta-v1_tabpfn_lora",
           "bert_passthrough",
           "passthrough",
           0.00001,
           600,
           35,
           10,
           0.8,
           true,
           "subset"
          ]
         ],
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "n_epochs=%{customdata[6]}<br>dimension_reduction=%{customdata[9]}<br>Accuracy=%{x}<br>Dataset=%{y}<br>Model=%{customdata[0]}<br>encoding=%{customdata[1]}<br>numerical_transformer=%{customdata[2]}<br>lr=%{customdata[3]}<br>single_eval_pos_train=%{customdata[4]}<br>dim_tabpfn=%{customdata[5]}<br>prop_train=%{customdata[7]}<br>disable_dropout=%{customdata[8]}<extra></extra>",
         "legendgroup": "10",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#00cc96"
         },
         "name": "10",
         "offsetgroup": "10",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": false,
         "type": "box",
         "x": [
          0.8983000000000001,
          0.9015000000000001,
          0.9120000000000001,
          0.9118,
          0.8985,
          0.9004,
          0.9105000000000001,
          0.9135,
          0.5612,
          0.5711999999999999,
          0.5698000000000001,
          0.5650000000000001,
          0.5625,
          0.5588,
          0.5671999999999999,
          0.5659,
          0.638,
          0.6375,
          0.6357,
          0.6368,
          0.6382,
          0.6353,
          0.6365999999999999,
          0.6361,
          0.8001000000000001,
          0.7943,
          0.7962,
          0.7927000000000001,
          0.7962,
          0.7929,
          0.7971,
          0.7887000000000001
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "employee_salary",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "journal_jcr_cls",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "museums",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify",
          "spotify"
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {},
          "showarrow": false,
          "text": "dimension_reduction=subset",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.15666666666666665,
          "yanchor": "middle",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "dimension_reduction=pca",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.4999999999999999,
          "yanchor": "middle",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "dimension_reduction=linear",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.8433333333333332,
          "yanchor": "middle",
          "yref": "paper"
         }
        ],
        "boxmode": "group",
        "height": 1000,
        "legend": {
         "title": {
          "text": "n_epochs"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Swarm Plot of Model Accuracies Across Datasets"
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.98
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          0.98
         ],
         "matches": "x",
         "showticklabels": false
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.98
         ],
         "matches": "x",
         "showticklabels": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          0.3133333333333333
         ],
         "title": {
          "text": "Dataset"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.34333333333333327,
          0.6566666666666665
         ],
         "matches": "y",
         "title": {
          "text": "Dataset"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.6866666666666665,
          0.9999999999999998
         ],
         "matches": "y",
         "title": {
          "text": "Dataset"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"372ae25b-e44b-44e0-8554-f665b2194465\" class=\"plotly-graph-div\" style=\"height:1000px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"372ae25b-e44b-44e0-8554-f665b2194465\")) {                    Plotly.newPlot(                        \"372ae25b-e44b-44e0-8554-f665b2194465\",                        [{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"customdata\":[[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"linear\"]],\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"n_epochs=%{customdata[6]}\\u003cbr\\u003edimension_reduction=%{customdata[9]}\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003eDataset=%{y}\\u003cbr\\u003eModel=%{customdata[0]}\\u003cbr\\u003eencoding=%{customdata[1]}\\u003cbr\\u003enumerical_transformer=%{customdata[2]}\\u003cbr\\u003elr=%{customdata[3]}\\u003cbr\\u003esingle_eval_pos_train=%{customdata[4]}\\u003cbr\\u003edim_tabpfn=%{customdata[5]}\\u003cbr\\u003eprop_train=%{customdata[7]}\\u003cbr\\u003edisable_dropout=%{customdata[8]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#636efa\"},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":true,\"x\":[0.8805999999999999,0.8807,0.907,0.907,0.8836999999999999,0.8839,0.9057000000000001,0.9048999999999999,0.5621,0.5599000000000001,0.5700000000000001,0.5671999999999999,0.5591,0.5589000000000001,0.5722,0.5671,0.648,0.6418,0.6431,0.6372,0.6481,0.6439,0.6363,0.6428,0.7687999999999999,0.7662,0.787,0.7838,0.7653,0.7639,0.7812,0.7846],\"x0\":\" \",\"xaxis\":\"x3\",\"y\":[\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y3\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"customdata\":[[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"pca\"]],\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"n_epochs=%{customdata[6]}\\u003cbr\\u003edimension_reduction=%{customdata[9]}\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003eDataset=%{y}\\u003cbr\\u003eModel=%{customdata[0]}\\u003cbr\\u003eencoding=%{customdata[1]}\\u003cbr\\u003enumerical_transformer=%{customdata[2]}\\u003cbr\\u003elr=%{customdata[3]}\\u003cbr\\u003esingle_eval_pos_train=%{customdata[4]}\\u003cbr\\u003edim_tabpfn=%{customdata[5]}\\u003cbr\\u003eprop_train=%{customdata[7]}\\u003cbr\\u003edisable_dropout=%{customdata[8]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#636efa\"},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":false,\"x\":[0.8940999999999999,0.8949,0.9141,0.9132999999999999,0.8934,0.8932,0.9146000000000001,0.9129999999999999,0.5727,0.5746,0.5948,0.5949,0.5742,0.5742,0.5934,0.5926,0.6504,0.65,0.6418,0.643,0.6505,0.6492,0.6424,0.642,0.8295999999999999,0.8305999999999999,0.8231999999999999,0.8244,0.8294,0.8304,0.8252,0.8246],\"x0\":\" \",\"xaxis\":\"x2\",\"y\":[\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y2\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"customdata\":[[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,0,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,0,0.8,true,\"subset\"]],\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"n_epochs=%{customdata[6]}\\u003cbr\\u003edimension_reduction=%{customdata[9]}\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003eDataset=%{y}\\u003cbr\\u003eModel=%{customdata[0]}\\u003cbr\\u003eencoding=%{customdata[1]}\\u003cbr\\u003enumerical_transformer=%{customdata[2]}\\u003cbr\\u003elr=%{customdata[3]}\\u003cbr\\u003esingle_eval_pos_train=%{customdata[4]}\\u003cbr\\u003edim_tabpfn=%{customdata[5]}\\u003cbr\\u003eprop_train=%{customdata[7]}\\u003cbr\\u003edisable_dropout=%{customdata[8]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#636efa\"},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":false,\"x\":[0.8901,0.8901,0.9093,0.9093,0.8901,0.8901,0.9093,0.9093,0.5582,0.5582,0.5626,0.5626,0.5582,0.5582,0.5626,0.5626,0.6375,0.6375,0.6346,0.6346,0.6375,0.6375,0.6345,0.6345,0.7615999999999999,0.7615999999999999,0.787,0.7870999999999999,0.7615999999999999,0.7615999999999999,0.7870999999999999,0.7870999999999999],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"customdata\":[[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"linear\"]],\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"n_epochs=%{customdata[6]}\\u003cbr\\u003edimension_reduction=%{customdata[9]}\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003eDataset=%{y}\\u003cbr\\u003eModel=%{customdata[0]}\\u003cbr\\u003eencoding=%{customdata[1]}\\u003cbr\\u003enumerical_transformer=%{customdata[2]}\\u003cbr\\u003elr=%{customdata[3]}\\u003cbr\\u003esingle_eval_pos_train=%{customdata[4]}\\u003cbr\\u003edim_tabpfn=%{customdata[5]}\\u003cbr\\u003eprop_train=%{customdata[7]}\\u003cbr\\u003edisable_dropout=%{customdata[8]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"1\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#EF553B\"},\"name\":\"1\",\"offsetgroup\":\"1\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":true,\"x\":[0.8874000000000001,0.8903000000000001,0.908,0.9099999999999999,0.8825,0.8846,0.9117000000000001,0.9080999999999999,0.5573,0.5605,0.5767,0.5740000000000001,0.5561,0.5649,0.5726,0.5677,0.6416000000000001,0.6420999999999999,0.641,0.642,0.6344000000000001,0.6407,0.6359999999999999,0.6405000000000001,0.7745,0.7724,0.7932,0.796,0.7662,0.7713,0.7863,0.7802],\"x0\":\" \",\"xaxis\":\"x3\",\"y\":[\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y3\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"customdata\":[[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"pca\"]],\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"n_epochs=%{customdata[6]}\\u003cbr\\u003edimension_reduction=%{customdata[9]}\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003eDataset=%{y}\\u003cbr\\u003eModel=%{customdata[0]}\\u003cbr\\u003eencoding=%{customdata[1]}\\u003cbr\\u003enumerical_transformer=%{customdata[2]}\\u003cbr\\u003elr=%{customdata[3]}\\u003cbr\\u003esingle_eval_pos_train=%{customdata[4]}\\u003cbr\\u003edim_tabpfn=%{customdata[5]}\\u003cbr\\u003eprop_train=%{customdata[7]}\\u003cbr\\u003edisable_dropout=%{customdata[8]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"1\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#EF553B\"},\"name\":\"1\",\"offsetgroup\":\"1\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":false,\"x\":[0.8946,0.8962,0.9138,0.9146000000000001,0.8932,0.8966999999999998,0.9136,0.9141999999999999,0.5765,0.5753,0.5944,0.5942999999999999,0.5745,0.5795,0.5947,0.5939,0.6515,0.6522,0.6435,0.6423,0.6533,0.6521,0.6429,0.6424,0.8302999999999999,0.8305,0.8257999999999999,0.8234999999999999,0.8303,0.8311999999999999,0.8242,0.8241999999999999],\"x0\":\" \",\"xaxis\":\"x2\",\"y\":[\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y2\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"customdata\":[[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,1,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,1,0.8,true,\"subset\"]],\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"n_epochs=%{customdata[6]}\\u003cbr\\u003edimension_reduction=%{customdata[9]}\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003eDataset=%{y}\\u003cbr\\u003eModel=%{customdata[0]}\\u003cbr\\u003eencoding=%{customdata[1]}\\u003cbr\\u003enumerical_transformer=%{customdata[2]}\\u003cbr\\u003elr=%{customdata[3]}\\u003cbr\\u003esingle_eval_pos_train=%{customdata[4]}\\u003cbr\\u003edim_tabpfn=%{customdata[5]}\\u003cbr\\u003eprop_train=%{customdata[7]}\\u003cbr\\u003edisable_dropout=%{customdata[8]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"1\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#EF553B\"},\"name\":\"1\",\"offsetgroup\":\"1\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":false,\"x\":[0.8919,0.8939999999999999,0.9096,0.9107,0.8916999999999999,0.8924,0.9086000000000001,0.9093,0.5574,0.5586,0.564,0.5654,0.5591,0.5586,0.5636,0.5650999999999999,0.6357999999999999,0.6355999999999999,0.6347,0.6332,0.6348,0.6345,0.6338999999999999,0.6362,0.7684,0.7683,0.79,0.7898,0.7689,0.7668999999999999,0.7911,0.7895],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"customdata\":[[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"linear\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"linear\"]],\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"n_epochs=%{customdata[6]}\\u003cbr\\u003edimension_reduction=%{customdata[9]}\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003eDataset=%{y}\\u003cbr\\u003eModel=%{customdata[0]}\\u003cbr\\u003eencoding=%{customdata[1]}\\u003cbr\\u003enumerical_transformer=%{customdata[2]}\\u003cbr\\u003elr=%{customdata[3]}\\u003cbr\\u003esingle_eval_pos_train=%{customdata[4]}\\u003cbr\\u003edim_tabpfn=%{customdata[5]}\\u003cbr\\u003eprop_train=%{customdata[7]}\\u003cbr\\u003edisable_dropout=%{customdata[8]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"10\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#00cc96\"},\"name\":\"10\",\"offsetgroup\":\"10\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":true,\"x\":[0.9064,0.9019,0.9074,0.9088,0.9000999999999999,0.9006000000000001,0.908,0.9076000000000001,0.568,0.5705,0.5779,0.578,0.5740000000000001,0.5652,0.5730999999999999,0.5758,0.6452,0.6365000000000001,0.6359,0.6368,0.6453,0.6323,0.6407,0.6345000000000001,0.8,0.8023,0.8006,0.7978,0.7943,0.7985,0.7997,0.792],\"x0\":\" \",\"xaxis\":\"x3\",\"y\":[\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y3\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"customdata\":[[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"pca\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"pca\"]],\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"n_epochs=%{customdata[6]}\\u003cbr\\u003edimension_reduction=%{customdata[9]}\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003eDataset=%{y}\\u003cbr\\u003eModel=%{customdata[0]}\\u003cbr\\u003eencoding=%{customdata[1]}\\u003cbr\\u003enumerical_transformer=%{customdata[2]}\\u003cbr\\u003elr=%{customdata[3]}\\u003cbr\\u003esingle_eval_pos_train=%{customdata[4]}\\u003cbr\\u003edim_tabpfn=%{customdata[5]}\\u003cbr\\u003eprop_train=%{customdata[7]}\\u003cbr\\u003edisable_dropout=%{customdata[8]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"10\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#00cc96\"},\"name\":\"10\",\"offsetgroup\":\"10\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":false,\"x\":[0.9071999999999999,0.9080999999999999,0.9144,0.9157,0.9010999999999999,0.9012,0.9148999999999999,0.9141,0.5825,0.5838,0.597,0.597,0.5824,0.5861000000000001,0.5944,0.5967,0.6565,0.6571,0.6463,0.6413,0.6529999999999999,0.6532,0.6436,0.6424,0.8308,0.8301000000000001,0.8237,0.8248,0.8311,0.8311999999999999,0.8236000000000001,0.8243],\"x0\":\" \",\"xaxis\":\"x2\",\"y\":[\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y2\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"customdata\":[[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,10,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,400,35,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,10,10,0.8,true,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,false,\"subset\"],[\"sentence-transformers\\u002fall-distilroberta-v1_tabpfn_lora\",\"bert_passthrough\",\"passthrough\",0.00001,600,35,10,0.8,true,\"subset\"]],\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"n_epochs=%{customdata[6]}\\u003cbr\\u003edimension_reduction=%{customdata[9]}\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003eDataset=%{y}\\u003cbr\\u003eModel=%{customdata[0]}\\u003cbr\\u003eencoding=%{customdata[1]}\\u003cbr\\u003enumerical_transformer=%{customdata[2]}\\u003cbr\\u003elr=%{customdata[3]}\\u003cbr\\u003esingle_eval_pos_train=%{customdata[4]}\\u003cbr\\u003edim_tabpfn=%{customdata[5]}\\u003cbr\\u003eprop_train=%{customdata[7]}\\u003cbr\\u003edisable_dropout=%{customdata[8]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"10\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#00cc96\"},\"name\":\"10\",\"offsetgroup\":\"10\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":false,\"x\":[0.8983000000000001,0.9015000000000001,0.9120000000000001,0.9118,0.8985,0.9004,0.9105000000000001,0.9135,0.5612,0.5711999999999999,0.5698000000000001,0.5650000000000001,0.5625,0.5588,0.5671999999999999,0.5659,0.638,0.6375,0.6357,0.6368,0.6382,0.6353,0.6365999999999999,0.6361,0.8001000000000001,0.7943,0.7962,0.7927000000000001,0.7962,0.7929,0.7971,0.7887000000000001],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"employee_salary\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"journal_jcr_cls\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"museums\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\",\"spotify\"],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.98],\"title\":{\"text\":\"Accuracy\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,0.3133333333333333],\"title\":{\"text\":\"Dataset\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.98],\"matches\":\"x\",\"showticklabels\":false},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.34333333333333327,0.6566666666666665],\"matches\":\"y\",\"title\":{\"text\":\"Dataset\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.98],\"matches\":\"x\",\"showticklabels\":false},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.6866666666666665,0.9999999999999998],\"matches\":\"y\",\"title\":{\"text\":\"Dataset\"}},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"dimension_reduction=subset\",\"textangle\":90,\"x\":0.98,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":0.15666666666666665,\"yanchor\":\"middle\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"dimension_reduction=pca\",\"textangle\":90,\"x\":0.98,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":0.4999999999999999,\"yanchor\":\"middle\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"dimension_reduction=linear\",\"textangle\":90,\"x\":0.98,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":0.8433333333333332,\"yanchor\":\"middle\",\"yref\":\"paper\"}],\"legend\":{\"title\":{\"text\":\"n_epochs\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Swarm Plot of Model Accuracies Across Datasets\"},\"boxmode\":\"group\",\"height\":1000,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('372ae25b-e44b-44e0-8554-f665b2194465');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "##df = pd.read_csv(\"../results/results.csv\")\n",
    "\n",
    "\n",
    "# add new rows with test accuracies\n",
    "#new_rows = {\"dataset\": [\"spotify\"] * 5, \"model\": [\"bert\"] * 5, \"dim_reduction\": [\"none\"] * 5, \"encoding\": [\"lm__all-MiniLM-L12-v2\"] * 5, \"accuracy\": test_accuracies}\n",
    "#df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "cols_to_consider = ['dataset', 'model', 'encoding', \"numerical_transformer\", \"lr\", \"single_eval_pos_train\", \"dim_tabpfn\", \"n_epochs\",\n",
    "                                  \"prop_train\", \"disable_dropout\", \"dimension_reduction\"]\n",
    "results_ = results[cols_to_consider + [\"accuracy\"]]\n",
    "melted_results = results_.groupby(cols_to_consider).mean().reset_index()\n",
    "\n",
    "hue_var = \"n_epochs\"\n",
    "fig = px.strip(\n",
    "    data_frame=melted_results,\n",
    "    x=\"accuracy\",\n",
    "    y=\"dataset\",\n",
    "    color=hue_var,\n",
    "    #color=\"dim_reduction\",\n",
    "    facet_row=\"dimension_reduction\",\n",
    "    hover_data=cols_to_consider,\n",
    "    title=\"Swarm Plot of Model Accuracies Across Datasets\",\n",
    "    labels={\"accuracy\": \"Accuracy\", \"dataset\": \"Dataset\", \"model\": \"Model\"},\n",
    "    height=1000,\n",
    "    width=900,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(len(all_train_losses)):\n",
    "    plt.plot(all_train_losses[i], label=\"train\")\n",
    "    plt.plot(all_val_losses[i], label=\"val\")\n",
    "    plt.hlines(test_losses[i], 0, len(all_train_losses[i]), label=\"test\", linestyle=\"dashed\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.plot(all_train_accuracies[i], label=\"train acc\")\n",
    "    plt.plot(all_val_accuracies[i], label=\"val acc\")\n",
    "    plt.hlines(test_accuracies[i], 0, len(all_val_accuracies[i]), label=\"test acc\", linestyle=\"dashed\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import FixedSizeSplit\n",
    "import pandas as pd\n",
    "cv = FixedSizeSplit(n_splits=5, n_train=1000, n_test=4000)\n",
    "transformer_name = \"distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)\n",
    "datasets = [\"journal_jcr_cls\", \"movies\", \"michelin\", \"spotify\", \"employee_salary\", \"museums\", \"fifa_footballplayers_22\", \"jp_anime\"]\n",
    "results = pd.DataFrame(columns=[\"dataset\", \"encoding\", \"dim_reduction\", \"model\", \"accuracy\"])\n",
    "for dataset in datasets:\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    X, y = load_data(dataset, max_rows=10000\n",
    "    # label encoding\n",
    "    #y = y.astype('category').cat.codes\n",
    "    y = y.astype(np.int64)\n",
    "    texts = X.tolist()\n",
    "    all_encoding = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = {k: v[train_index] for k, v in all_encoding.items()}, {k: v[test_index] for k, v in all_encoding.items()}\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        #model, input_ids_train, attention_mask_train, labels_train = train_model(X_train, y_train, transformer_name=transformer_name)\n",
    "        model, input_ids_train, attention_mask_train, labels_train = train_model(X_train, y_train, transformer_name=transformer_name)\n",
    "        print(\"Finished training\")\n",
    "        # Evaluate on test set\n",
    "        # create a test dataset\n",
    "        \n",
    "\n",
    "        test_dataset = CustomDataset(X_test, torch.tensor(y_test).float().reshape(-1, 1))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "        test_loss, test_accuracy = evaluate_model(test_loader, model, input_ids_train, attention_mask_train, labels_train)\n",
    "        print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        del input_ids_train, attention_mask_train, labels_train, model\n",
    "        torch.cuda.empty_cache()\n",
    "    # print memory usage\n",
    "    #print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "    \n",
    "    results = pd.concat([results, pd.DataFrame({\"dataset\": [dataset] * 5, \"encoding\": [\"bert\"] * 5, \"dim_reduction\": [\"none\"] * 5, \"model\": [\"bert\"] * 5, \"accuracy\": test_accuracies.copy()})])\n",
    "    results.to_csv(\"results_training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd lm_tab/scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show column singe_eval_pos_train\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "#df = pd.read_csv(\"../results/results.csv\")\n",
    "#df = pd.read_csv(\"results_with_numerics.csv\")\n",
    "df = pd.read_csv(\"results_tabfn_basic.csv\")\n",
    "print(df[\"model\"].unique())\n",
    "df_new = pd.read_csv(\"results_training_with_numerics.csv\")\n",
    "df_new_bis = pd.read_csv(\"results_training_with_numerics_lora.csv\")\n",
    "default_values = {\"n_epochs\": 1, \n",
    "                    \"lr\": 1e-5,\n",
    "                    \"single_eval_pos_train\": 500,\n",
    "                    \"dim_tabpfn\": 20,\n",
    "                    \"numerical_transformer\": \"passthrough\"}\n",
    "to_vary = \"n_epochs\"\n",
    "for col_name, default_value in default_values.items():\n",
    "    if col_name == to_vary:\n",
    "        continue\n",
    "    df_new = df_new[df_new[col_name] == default_value]\n",
    "#df_new = pd.read_csv(\"results_training.csv\")\n",
    "#df = df[df[\"dataset\"] == \"spotify\"]\n",
    "df = pd.concat([df, df_new, df_new_bis], ignore_index=True)\n",
    "# replace nans with \"missing\" for all columns\n",
    "df = df.fillna(\"missing\")\n",
    "\n",
    "# add new rows with test accuracies\n",
    "#new_rows = {\"dataset\": [\"spotify\"] * 5, \"model\": [\"bert\"] * 5, \"dim_reduction\": [\"none\"] * 5, \"encoding\": [\"lm__all-MiniLM-L12-v2\"] * 5, \"accuracy\": test_accuracies}\n",
    "#df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "melted_results = df.groupby(['dataset', 'model', 'dim_reduction', 'encoding', \"numerical_transformer\", \"lr\", \"single_eval_pos_train\", \"dim_tabpfn\", \"n_epochs\"]).mean().reset_index()\n",
    "#melted_results = results.explode('accuracy')\n",
    "#melted_results['accuracy'] = melted_results['accuracy'].astype(float)\n",
    "#melted_results = melted_results[melted_results['encoding'] == 'lm__all-MiniLM-L12-v2']\n",
    "\n",
    "\n",
    "# Creating the swarmplot\n",
    "# plt.figure(figsize=(15, 20))\n",
    "# sns.swarmplot(data=melted_results, x='accuracy', y='dataset', hue='model', dodge=True)\n",
    "# plt.title('Swarm Plot of Model Accuracies Across Datasets')\n",
    "# plt.xlabel('Accuracy')\n",
    "# plt.ylabel('Dataset')\n",
    "# plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.show()\n",
    "# Create the plot\n",
    "#hue_var = to_vary\n",
    "hue_var = \"model\"\n",
    "fig = px.strip(\n",
    "    data_frame=melted_results,\n",
    "    x=\"accuracy\",\n",
    "    y=\"dataset\",\n",
    "    color=hue_var,\n",
    "    #color=\"dim_reduction\",\n",
    "    title=\"Swarm Plot of Model Accuracies Across Datasets\",\n",
    "    labels={\"accuracy\": \"Accuracy\", \"dataset\": \"Dataset\", \"model\": \"Model\"},\n",
    "    height=600,\n",
    "    width=900,\n",
    ")\n",
    "\n",
    "# Update hover information for each trace (grouped by 'color' or 'model' in this case)\n",
    "for i, trace in enumerate(fig.data):\n",
    "    subset_df = melted_results[melted_results[hue_var] == trace.name]\n",
    "    hover_template = \"<br>\".join([f\"{col}: %{{customdata[{i}]}}\" for i, col in enumerate(subset_df.columns)])\n",
    "    trace.customdata = subset_df.values\n",
    "    trace.hovertemplate = hover_template\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoModel\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoModel\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "model_name_or_path = \"distilroberta-base\"\n",
    "tokenizer_name_or_path = \"distilroberta-base\"\n",
    "\n",
    "peft_config = LoraConfig(inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name_or_path)\n",
    "print(\"Loaded model\")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.utils import preprocess_input\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "\n",
    "# Your text data and labels (replace these with your actual data and labels)\n",
    "# Your text data and labels (replace these with your actual data and labels)\n",
    "#texts = X_original[column_to_consider].tolist()\n",
    "texts = X.tolist()\n",
    "#labels = (y_original > np.median(y_original)).tolist()\n",
    "#labels = y_original.tolist()\n",
    "labels = y.tolist()\n",
    "\n",
    "# Tokenize the text data\n",
    "#encoding = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Create a custom dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "#dataset = CustomDataset(encoding, torch.tensor(labels).float().reshape(-1, 1))\n",
    "#print(f\"Dataset size: {len(dataset)}\")\n",
    "train_size = 700\n",
    "val_size = 1000 #TODO\n",
    "\n",
    "all_encoding = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "encoding_train = {k: v[:train_size] for k, v in all_encoding.items()}\n",
    "encoding_val = {k: v[train_size:train_size+val_size] for k, v in all_encoding.items()}\n",
    "encoding_test = {k: v[train_size+val_size:] for k, v in all_encoding.items()}\n",
    "train_dataset = CustomDataset(encoding_train, torch.tensor(labels).float().reshape(-1, 1)[:train_size])\n",
    "val_dataset = CustomDataset(encoding_val, torch.tensor(labels).float().reshape(-1, 1)[train_size:train_size+val_size])\n",
    "test_dataset = CustomDataset(encoding_test, torch.tensor(labels).float().reshape(-1, 1)[train_size+val_size:])\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "#model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model = BertAndTabPFN(preprocess_before_tabpfn=True, linear_translator=False).to('cuda')\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "es_patience = 5\n",
    "es_tolerance = 1e-4\n",
    "es_counter = 0\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "best_val_loss = np.inf\n",
    "for epoch in range(num_epochs):\n",
    "    if es_counter >= es_patience:\n",
    "        break\n",
    "    ###########\n",
    "    # Train loop\n",
    "    model.train()\n",
    "    train_preds, train_labels, train_losses = [], [], []\n",
    "    for batch in train_loader:\n",
    "        input_ids_train = batch['input_ids']\n",
    "        attention_mask_train = batch['attention_mask']\n",
    "        labels_train = batch['labels']\n",
    "        # move the inputs to GPU\n",
    "        input_ids_train = input_ids_train.to('cuda')\n",
    "        attention_mask_train = attention_mask_train.to('cuda')\n",
    "        labels_train = labels_train.to('cuda')\n",
    "        single_eval_pos = 400\n",
    "        output = model(input_ids_train, attention_mask=attention_mask_train, y=labels_train, single_eval_pos=single_eval_pos).squeeze()\n",
    "        loss = nn.CrossEntropyLoss()(output, labels_train[single_eval_pos:].long().reshape(-1))\n",
    "        if epoch > 0:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # compute train accuracy\n",
    "        preds = torch.argmax(output, axis=-1).cpu().detach().numpy()\n",
    "        #train_accuracy = accuracy_score(labels_train[single_eval_pos:].cpu().detach().numpy().reshape(-1), preds)\n",
    "        #print(f\"Epoch {epoch + 1} - Training loss: {loss}, Training accuracy: {train_accuracy}\")\n",
    "        train_losses.append(loss.cpu().item())\n",
    "        train_preds.append(preds)\n",
    "        train_labels.append(labels_train[single_eval_pos:].cpu().detach().numpy().reshape(-1))\n",
    "    train_preds = np.concatenate(train_preds)\n",
    "    train_labels = np.concatenate(train_labels)\n",
    "    train_losses = np.mean(train_losses)\n",
    "    print(f\"Epoch {epoch + 1} - Training loss: {train_losses}, Training accuracy: {accuracy_score(train_labels, train_preds)}\")\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_preds, val_labels, val_losses = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader: #TODO: remove the useless for loop\n",
    "            input_ids_val = batch['input_ids']\n",
    "            attention_mask_val = batch['attention_mask']\n",
    "            labels_val = batch['labels']\n",
    "            # move the inputs to GPU\n",
    "            input_ids_val = input_ids_val.to('cuda')\n",
    "            attention_mask_val = attention_mask_val.to('cuda')\n",
    "            labels_val = labels_val.to('cuda')\n",
    "            # concatenate train and val\n",
    "            #TODO: make sure this is correct, no leak etc\n",
    "            # maybe safer to create a TabPFNClassifier with the same parameters as the one in BertAndTabPFN\n",
    "            input_ids = torch.cat((input_ids_train, input_ids_val), axis=0)\n",
    "            attention_mask = torch.cat((attention_mask_train, attention_mask_val), axis=0)\n",
    "            labels = torch.cat((labels_train, labels_val), axis=0)\n",
    "            single_eval_pos = train_size\n",
    "            output = model(input_ids, attention_mask=attention_mask, y=labels, single_eval_pos=single_eval_pos).squeeze()\n",
    "            val_loss = nn.CrossEntropyLoss()(output, labels[single_eval_pos:].long().reshape(-1))\n",
    "            if val_loss < best_val_loss - es_tolerance:\n",
    "                print(f\"Validation loss decreased from {best_val_loss} to {val_loss}\")\n",
    "                best_val_loss = val_loss\n",
    "                # save the model\n",
    "                torch.save(model.state_dict(), \"checkpoints/model.pt\")\n",
    "                # save input_ids_train, attention_mask_train, labels_train\n",
    "                torch.save(input_ids_train, \"checkpoints/input_ids_train.pt\")\n",
    "                torch.save(attention_mask_train, \"checkpoints/attention_mask_train.pt\")\n",
    "                torch.save(labels_train, \"checkpoints/labels_train.pt\")\n",
    "            else:\n",
    "                es_counter += 1\n",
    "                print(f\"Early stopping counter: {es_counter}\")\n",
    "                if es_counter >= es_patience:\n",
    "                    print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                    break\n",
    "\n",
    "\n",
    "            val_losses.append(val_loss.cpu())\n",
    "            preds = torch.argmax(output, axis=-1).cpu().detach().numpy()\n",
    "            val_preds.append(preds)\n",
    "            val_labels.append(labels[single_eval_pos:].cpu().detach().numpy().reshape(-1))\n",
    "        else:\n",
    "            val_preds = np.concatenate(val_preds)\n",
    "            val_labels = np.concatenate(val_labels)\n",
    "            val_losses = np.mean(val_losses)\n",
    "            print(f\"Epoch {epoch + 1} - Validation loss: {val_losses}\")\n",
    "            # Compute accuracy\n",
    "            val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "            print(f\"Epoch {epoch + 1} - Validation accuracy: {val_accuracy}\")\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"checkpoints/model.pt\"))\n",
    "input_ids_train = torch.load(\"checkpoints/input_ids_train.pt\")\n",
    "attention_mask_train = torch.load(\"checkpoints/attention_mask_train.pt\")\n",
    "labels_train = torch.load(\"checkpoints/labels_train.pt\")\n",
    "\n",
    "# Test loop\n",
    "model.eval()\n",
    "test_preds, test_labels, test_losses = [], [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids_test = batch['input_ids']\n",
    "        attention_mask_test = batch['attention_mask']\n",
    "        labels_test = batch['labels']\n",
    "        # move the inputs to GPU\n",
    "        input_ids_test = input_ids_test.to('cuda')\n",
    "        attention_mask_test = attention_mask_test.to('cuda')\n",
    "        labels_test = labels_test.to('cuda')\n",
    "        # concatenate train and val\n",
    "        #TODO put this back\n",
    "        #input_ids = torch.cat((input_ids_train, input_ids_test), axis=0)\n",
    "        #attention_mask = torch.cat((attention_mask_train, attention_mask_test), axis=0)\n",
    "        #labels = torch.cat((labels_train, labels_test), axis=0)\n",
    "        single_eval_pos = train_size\n",
    "\n",
    "        output = model(input_ids_test, attention_mask=attention_mask_test, y=labels_test, single_eval_pos=single_eval_pos).squeeze()\n",
    "        test_loss = nn.CrossEntropyLoss()(output, labels_test[single_eval_pos:].long().reshape(-1))\n",
    "        test_losses.append(test_loss.cpu())\n",
    "        preds = torch.argmax(output, axis=-1).cpu().detach().numpy()\n",
    "        test_preds.append(preds)\n",
    "        test_labels.append(labels_test[single_eval_pos:].cpu().detach().numpy().reshape(-1))\n",
    "\n",
    "test_preds = np.concatenate(test_preds)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "test_losses = np.mean(test_losses)\n",
    "print(f\"Test loss: {test_losses}\")\n",
    "print(f\"Test accuracy: {accuracy_score(test_labels, test_preds)}\")\n",
    "\n",
    "# Save the model\n",
    "# model.save_pretrained(\"./fine_tuned_bert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(input_ids_train, \"checkpoints/input_ids_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
