{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/lgrinszt/lm_tab/scripts\n"
     ]
    }
   ],
   "source": [
    "%cd lm_tab/scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cities = pd.read_csv(\"../data/cities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "cities = cities.rename(columns={\"Official est. GDP\\nup to date\\n(billion US$)\": \"gdp\", \"Metropolitan population\": \"pop\", \"Official est. GDP per capita\": \"gdp_capita\",\n",
    "                                \"City proper/metropolitan area\": \"city\", \"Country/region\": \"country\"})\n",
    "cities = cities.drop(columns=[\"Rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>gdp</th>\n",
       "      <th>pop</th>\n",
       "      <th>gdp_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford, British Columbia</td>\n",
       "      <td>Canada</td>\n",
       "      <td>6.141 (2019)</td>\n",
       "      <td>202,497 (2019)</td>\n",
       "      <td>30,321.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>23.0 (2020)</td>\n",
       "      <td>489,840 (2020)</td>\n",
       "      <td>46,957.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abidjan</td>\n",
       "      <td>Ivory Coast</td>\n",
       "      <td>27 (2017)</td>\n",
       "      <td>5,950,000 (2022)</td>\n",
       "      <td>4,537.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>119 (2015)</td>\n",
       "      <td>1,660,000 (2022)</td>\n",
       "      <td>71,686.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Australia</td>\n",
       "      <td>64.461 (2018–19)</td>\n",
       "      <td>1,380,000 (2022)</td>\n",
       "      <td>46,710.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Padua–Treviso–Venice metropolitan area</td>\n",
       "      <td>Italy</td>\n",
       "      <td>34.837 (2020)</td>\n",
       "      <td>2,748,420 (2020)</td>\n",
       "      <td>12,676.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Verona metropolitan area</td>\n",
       "      <td>Italy</td>\n",
       "      <td>34.152 (2020)</td>\n",
       "      <td>915,975 (2020)</td>\n",
       "      <td>37,282.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Heidelberg</td>\n",
       "      <td>Germany</td>\n",
       "      <td>34.038 (2020)</td>\n",
       "      <td>1,544,830 (2020)</td>\n",
       "      <td>22,034.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>Murcia</td>\n",
       "      <td>Spain</td>\n",
       "      <td>33.923 (2020)</td>\n",
       "      <td>1,528,828 (2020)</td>\n",
       "      <td>22,186.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>Zürich</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,470,000 (2022)</td>\n",
       "      <td>74,193.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       city               country  \\\n",
       "0              Abbotsford, British Columbia                Canada   \n",
       "1                                  Aberdeen        United Kingdom   \n",
       "2                                   Abidjan           Ivory Coast   \n",
       "3                                 Abu Dhabi  United Arab Emirates   \n",
       "4                                  Adelaide             Australia   \n",
       "..                                      ...                   ...   \n",
       "714  Padua–Treviso–Venice metropolitan area                 Italy   \n",
       "715                Verona metropolitan area                 Italy   \n",
       "716                              Heidelberg               Germany   \n",
       "717                                  Murcia                 Spain   \n",
       "718                                  Zürich           Switzerland   \n",
       "\n",
       "                  gdp               pop gdp_capita  \n",
       "0        6.141 (2019)    202,497 (2019)  30,321.44  \n",
       "1         23.0 (2020)    489,840 (2020)  46,957.94  \n",
       "2           27 (2017)  5,950,000 (2022)   4,537.82  \n",
       "3          119 (2015)  1,660,000 (2022)  71,686.75  \n",
       "4    64.461 (2018–19)  1,380,000 (2022)  46,710.87  \n",
       "..                ...               ...        ...  \n",
       "714     34.837 (2020)  2,748,420 (2020)  12,676.37  \n",
       "715     34.152 (2020)    915,975 (2020)  37,282.68  \n",
       "716     34.038 (2020)  1,544,830 (2020)  22,034.79  \n",
       "717     33.923 (2020)  1,528,828 (2020)  22,186.93  \n",
       "718               NaN  1,470,000 (2022)  74,193.88  \n",
       "\n",
       "[719 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert 300+,168 (2021), cleaned_str: 300+168\n",
      "Could not convert 300+,851 (2021), cleaned_str: 300+851\n",
      "Could not convert 300+,789 (2021), cleaned_str: 300+789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>gdp</th>\n",
       "      <th>pop</th>\n",
       "      <th>gdp_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford, British Columbia</td>\n",
       "      <td>Canada</td>\n",
       "      <td>6.141</td>\n",
       "      <td>202497.0</td>\n",
       "      <td>30321.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>23.000</td>\n",
       "      <td>489840.0</td>\n",
       "      <td>46957.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abidjan</td>\n",
       "      <td>Ivory Coast</td>\n",
       "      <td>27.000</td>\n",
       "      <td>5950000.0</td>\n",
       "      <td>4537.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>119.000</td>\n",
       "      <td>1660000.0</td>\n",
       "      <td>71686.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Australia</td>\n",
       "      <td>64.461</td>\n",
       "      <td>1380000.0</td>\n",
       "      <td>46710.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>Ingolstadt</td>\n",
       "      <td>Germany</td>\n",
       "      <td>35.637</td>\n",
       "      <td>197560.0</td>\n",
       "      <td>180400.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Padua–Treviso–Venice metropolitan area</td>\n",
       "      <td>Italy</td>\n",
       "      <td>34.837</td>\n",
       "      <td>2748420.0</td>\n",
       "      <td>12676.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Verona metropolitan area</td>\n",
       "      <td>Italy</td>\n",
       "      <td>34.152</td>\n",
       "      <td>915975.0</td>\n",
       "      <td>37282.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Heidelberg</td>\n",
       "      <td>Germany</td>\n",
       "      <td>34.038</td>\n",
       "      <td>1544830.0</td>\n",
       "      <td>22034.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>Murcia</td>\n",
       "      <td>Spain</td>\n",
       "      <td>33.923</td>\n",
       "      <td>1528828.0</td>\n",
       "      <td>22186.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       city               country      gdp  \\\n",
       "0              Abbotsford, British Columbia                Canada    6.141   \n",
       "1                                  Aberdeen        United Kingdom   23.000   \n",
       "2                                   Abidjan           Ivory Coast   27.000   \n",
       "3                                 Abu Dhabi  United Arab Emirates  119.000   \n",
       "4                                  Adelaide             Australia   64.461   \n",
       "..                                      ...                   ...      ...   \n",
       "713                              Ingolstadt               Germany   35.637   \n",
       "714  Padua–Treviso–Venice metropolitan area                 Italy   34.837   \n",
       "715                Verona metropolitan area                 Italy   34.152   \n",
       "716                              Heidelberg               Germany   34.038   \n",
       "717                                  Murcia                 Spain   33.923   \n",
       "\n",
       "           pop  gdp_capita  \n",
       "0     202497.0    30321.44  \n",
       "1     489840.0    46957.94  \n",
       "2    5950000.0     4537.82  \n",
       "3    1660000.0    71686.75  \n",
       "4    1380000.0    46710.87  \n",
       "..         ...         ...  \n",
       "713   197560.0   180400.89  \n",
       "714  2748420.0    12676.37  \n",
       "715   915975.0    37282.68  \n",
       "716  1544830.0    22034.79  \n",
       "717  1528828.0    22186.93  \n",
       "\n",
       "[682 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to clean the data\n",
    "import numpy as np\n",
    "def clean_numeric_data(value):\n",
    "    if isinstance(value, str):\n",
    "        cleaned_str = value.split('(')[0].replace(',', '').replace(\" \", \"\")\n",
    "        try:\n",
    "            return float(cleaned_str)\n",
    "        except:\n",
    "            print(f\"Could not convert {value}, cleaned_str: {cleaned_str}\")\n",
    "            return np.nan\n",
    "    return value\n",
    "\n",
    "# Apply the function to the relevant columns\n",
    "for col in ['gdp', 'pop', 'gdp_capita']:\n",
    "    cities[col] = cities[col].apply(clean_numeric_data)\n",
    "\n",
    "# drop rows with NaN values\n",
    "cities = cities.dropna()\n",
    "\n",
    "# Show the cleaned DataFrame\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2474542/900666696.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities[\"name\"] = cities[\"city\"] + \", \" + cities[\"country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loading import load_data\n",
    "from skrub import MinHashEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from src.utils import FeaturesExtractor, FixedSizeSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_toy_problem(df, problem_type=\"matching\"):\n",
    "    cities = df.copy()\n",
    "    if problem_type == \"capita\":\n",
    "        cities[\"per_capita\"] = np.random.uniform(0, 1, len(cities))\n",
    "        cities[\"num\"] = cities[\"pop\"] * cities[\"per_capita\"]\n",
    "        X_rest = cities[[\"per_capita\"]]\n",
    "        X_rest_with_pop = cities[[\"per_capita\", \"pop\"]]\n",
    "        X_text = cities[[\"name\"]]\n",
    "        y = cities[\"num\"] > np.median(cities[\"num\"])\n",
    "    elif problem_type == \"matching\":\n",
    "        pop_shufled = cities[\"pop\"].sample(frac=1).values\n",
    "        choices = np.random.choice([0, 1], size=len(cities), p=[0.5, 0.5])\n",
    "        # Based on the choices, create the 'new_pop' column\n",
    "        cities['new_pop'] = np.where(choices == 0, cities['pop'], pop_shufled)\n",
    "        # Store the choices as 'y'\n",
    "        y = choices\n",
    "        #X_rest = cities.drop(columns=[\"name\", \"city\", \"country\", \"gdp\"])\n",
    "        X_rest = cities[[\"new_pop\"]]\n",
    "        X_rest_with_pop = cities[[\"new_pop\", \"pop\"]]\n",
    "        X_text = cities[[\"name\"]]\n",
    "    return X_rest, X_rest_with_pop, X_text, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2474542/3570328819.py:80: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_2474542/3570328819.py:86: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data shape: (682, 768)\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2474542/3570328819.py:80: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_2474542/3570328819.py:86: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data shape: (682, 768)\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2474542/3570328819.py:80: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_2474542/3570328819.py:86: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data shape: (682, 768)\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2474542/3570328819.py:80: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_2474542/3570328819.py:86: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data shape: (682, 768)\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2474542/3570328819.py:80: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_2474542/3570328819.py:86: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data shape: (682, 768)\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "(682, 768) (682, 1) (682, 769)\n",
      "(682, 11)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "(682, 768) (682, 2) (682, 770)\n",
      "(682, 12)\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "from skrub import TableVectorizer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from  tabpfn import TabPFNClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from src.utils import run_on_encoded_data\n",
    "\n",
    "models = {\"TabPFNClassifier\": TabPFNClassifier(device=\"cpu\"), \"GradientBoostingClassifier\": GradientBoostingClassifier(), \"LogisticRegression\": LogisticRegression()}\n",
    "dim_reductions = {#\"subset_30\": FeaturesExtractor(method=\"first\", n_features=30),\n",
    "                  \"PCA_10\": PCA(n_components=10)}\n",
    "#                    \"passthrough\": \"passthrough\"}\n",
    "\n",
    "cv = FixedSizeSplit(n_splits=5, n_train=380, n_test=300, random_state=42)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=[\"dataset\", \"encoding\", \"dim_reduction\", \"model\", \"accuracy\"])\n",
    "\n",
    "dataset = \"pop\"\n",
    "encoding = \"lm__all-distilroberta-v1\"\n",
    "X_text = cities[\"name\"]\n",
    "\n",
    "for i in range(5):\n",
    "    X_rest, X_rest_with_pop, X_text, y = generate_toy_problem(cities, problem_type=dataset)\n",
    "    X_enc = encode(X_text, encoding)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # run with joblib\n",
    "    results_data_enc = Parallel(n_jobs=1)(delayed(run_on_encoded_data)(X_enc, X_rest, y, dim_reduction_name, dim_reduction,model_name, model) for (dim_reduction_name, dim_reduction) in dim_reductions.items() for (model_name, model) in models.items())\n",
    "    for dim_reduction_name, dim_reduction in dim_reductions.items():\n",
    "        for model_name, model in models.items():\n",
    "            scores = results_data_enc.pop(0)\n",
    "            if scores is None:\n",
    "                continue\n",
    "            results = pd.concat([results, pd.DataFrame({\"dataset\": dataset, \"encoding\": encoding, \"dim_reduction\": dim_reduction_name, \"model\": model_name, \"accuracy\": scores, \"features\": \"all\"})])\n",
    "\n",
    "    # same with X_rest = None\n",
    "    results_data_enc = Parallel(n_jobs=1)(delayed(run_on_encoded_data)(X_enc, None, y, dim_reduction_name, dim_reduction,model_name, model) for (dim_reduction_name, dim_reduction) in dim_reductions.items() for (model_name, model) in models.items())\n",
    "    for dim_reduction_name, dim_reduction in dim_reductions.items():\n",
    "        for model_name, model in models.items():\n",
    "            scores = results_data_enc.pop(0)\n",
    "            if scores is None:\n",
    "                continue\n",
    "            results = pd.concat([results, pd.DataFrame({\"dataset\": dataset, \"encoding\": encoding, \"dim_reduction\": dim_reduction_name, \"model\": model_name, \"accuracy\": scores, \"features\": \"text_only\"})])\n",
    "\n",
    "    results_data_enc = Parallel(n_jobs=1)(delayed(run_on_encoded_data)(None, X_rest, y, dim_reduction_name, dim_reduction,model_name, model) for (dim_reduction_name, dim_reduction) in dim_reductions.items() for (model_name, model) in models.items())\n",
    "    for dim_reduction_name, dim_reduction in dim_reductions.items():\n",
    "        for model_name, model in models.items():\n",
    "            scores = results_data_enc.pop(0)\n",
    "            if scores is None:\n",
    "                continue\n",
    "            results = pd.concat([results, pd.DataFrame({\"dataset\": dataset, \"encoding\": encoding, \"dim_reduction\": dim_reduction_name, \"model\": model_name, \"accuracy\": scores, \"features\": \"rest_only\"})])\n",
    "\n",
    "    # add pop to X_rest\n",
    "    results_data_enc = Parallel(n_jobs=1)(delayed(run_on_encoded_data)(X_enc, X_rest_with_pop, y, dim_reduction_name, dim_reduction,model_name, model) for (dim_reduction_name, dim_reduction) in dim_reductions.items() for (model_name, model) in models.items())\n",
    "    for dim_reduction_name, dim_reduction in dim_reductions.items():\n",
    "        for model_name, model in models.items():\n",
    "            scores = results_data_enc.pop(0)\n",
    "            if scores is None:\n",
    "                continue\n",
    "            results = pd.concat([results, pd.DataFrame({\"dataset\": dataset, \"encoding\": encoding, \"dim_reduction\": dim_reduction_name, \"model\": model_name, \"accuracy\": scores, \"features\": \"all_plus_pop\"})])\n",
    "    \n",
    "    # all rest + pop\n",
    "    X_rest_with_pop = cities[[\"pop\", \"new_pop\"]]\n",
    "    X_enc_none = None\n",
    "    results_data_enc = Parallel(n_jobs=1)(delayed(run_on_encoded_data)(None, X_rest_with_pop, y, dim_reduction_name, dim_reduction,model_name, model) for (dim_reduction_name, dim_reduction) in dim_reductions.items() for (model_name, model) in models.items())\n",
    "    for dim_reduction_name, dim_reduction in dim_reductions.items():\n",
    "        for model_name, model in models.items():\n",
    "            scores = results_data_enc.pop(0)\n",
    "            if scores is None:\n",
    "                continue\n",
    "            results = pd.concat([results, pd.DataFrame({\"dataset\": dataset, \"encoding\": encoding, \"dim_reduction\": dim_reduction_name, \"model\": model_name, \"accuracy\": scores, \"features\": \"rest_plus_pop\"})])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.75*0.75 + 0.25*0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "Model=TabPFNClassifier<br>Accuracy=%{x}<br>features=%{y}<extra></extra>",
         "legendgroup": "TabPFNClassifier",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#636efa"
         },
         "name": "TabPFNClassifier",
         "offsetgroup": "TabPFNClassifier",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": true,
         "type": "box",
         "x": [
          0.5933333333333334,
          0.6733333333333333,
          0.6233333333333333,
          0.6533333333333333,
          0.6733333333333333,
          0.49333333333333335,
          0.5066666666666667,
          0.49666666666666665,
          0.4866666666666667,
          0.47333333333333333,
          0.45,
          0.4166666666666667,
          0.48333333333333334,
          0.4866666666666667,
          0.45,
          0.86,
          0.94,
          0.8933333333333333,
          0.92,
          0.9266666666666666,
          0.9633333333333334,
          0.97,
          0.9666666666666667,
          0.9466666666666667,
          0.9566666666666667,
          0.65,
          0.63,
          0.6666666666666666,
          0.62,
          0.6166666666666667,
          0.5,
          0.5066666666666667,
          0.5,
          0.5,
          0.5066666666666667,
          0.5133333333333333,
          0.49,
          0.5,
          0.5,
          0.47,
          0.8533333333333334,
          0.8766666666666667,
          0.9066666666666666,
          0.89,
          0.9033333333333333,
          0.9466666666666667,
          0.9733333333333334,
          0.99,
          0.98,
          0.9766666666666667,
          0.6,
          0.6533333333333333,
          0.61,
          0.6333333333333333,
          0.6033333333333334,
          0.48333333333333334,
          0.4766666666666667,
          0.4666666666666667,
          0.52,
          0.5066666666666667,
          0.48333333333333334,
          0.4766666666666667,
          0.51,
          0.4866666666666667,
          0.51,
          0.9033333333333333,
          0.91,
          0.8833333333333333,
          0.7533333333333333,
          0.87,
          0.9766666666666667,
          0.9666666666666667,
          0.9766666666666667,
          0.9533333333333334,
          0.9433333333333334,
          0.6233333333333333,
          0.6633333333333333,
          0.6233333333333333,
          0.55,
          0.6433333333333333,
          0.52,
          0.5166666666666667,
          0.52,
          0.5066666666666667,
          0.5066666666666667,
          0.47,
          0.51,
          0.47333333333333333,
          0.5066666666666667,
          0.5066666666666667,
          0.82,
          0.91,
          0.8466666666666667,
          0.86,
          0.8766666666666667,
          0.97,
          0.9666666666666667,
          0.9533333333333334,
          0.9566666666666667,
          0.9366666666666666,
          0.59,
          0.6566666666666666,
          0.5866666666666667,
          0.58,
          0.65,
          0.5266666666666666,
          0.5166666666666667,
          0.5033333333333333,
          0.5066666666666667,
          0.5366666666666666,
          0.5266666666666666,
          0.53,
          0.49666666666666665,
          0.54,
          0.57,
          0.76,
          0.8666666666666667,
          0.92,
          0.7733333333333333,
          0.91,
          0.9666666666666667,
          0.92,
          0.9666666666666667,
          0.9666666666666667,
          0.97
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop"
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "Model=GradientBoostingClassifier<br>Accuracy=%{x}<br>features=%{y}<extra></extra>",
         "legendgroup": "GradientBoostingClassifier",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#EF553B"
         },
         "name": "GradientBoostingClassifier",
         "offsetgroup": "GradientBoostingClassifier",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": true,
         "type": "box",
         "x": [
          0.5266666666666666,
          0.52,
          0.5766666666666667,
          0.5633333333333334,
          0.5666666666666667,
          0.45,
          0.47333333333333333,
          0.49333333333333335,
          0.5066666666666667,
          0.5166666666666667,
          0.35333333333333333,
          0.38333333333333336,
          0.43,
          0.37666666666666665,
          0.41333333333333333,
          0.73,
          0.74,
          0.5933333333333334,
          0.6533333333333333,
          0.73,
          0.8966666666666666,
          0.9133333333333333,
          0.9066666666666666,
          0.8766666666666667,
          0.8866666666666667,
          0.5466666666666666,
          0.54,
          0.57,
          0.49,
          0.52,
          0.48,
          0.5066666666666667,
          0.5066666666666667,
          0.48,
          0.4666666666666667,
          0.38666666666666666,
          0.39666666666666667,
          0.38,
          0.4,
          0.38666666666666666,
          0.6366666666666667,
          0.7133333333333334,
          0.74,
          0.6566666666666666,
          0.7266666666666667,
          0.8733333333333333,
          0.8833333333333333,
          0.87,
          0.8766666666666667,
          0.8866666666666667,
          0.5633333333333334,
          0.52,
          0.5,
          0.58,
          0.51,
          0.5333333333333333,
          0.47,
          0.49666666666666665,
          0.47333333333333333,
          0.5066666666666667,
          0.39666666666666667,
          0.39666666666666667,
          0.42,
          0.4166666666666667,
          0.37333333333333335,
          0.6833333333333333,
          0.7266666666666667,
          0.7066666666666667,
          0.6966666666666667,
          0.67,
          0.8833333333333333,
          0.9,
          0.8733333333333333,
          0.8666666666666667,
          0.87,
          0.54,
          0.58,
          0.5466666666666666,
          0.5633333333333334,
          0.49666666666666665,
          0.53,
          0.5133333333333333,
          0.54,
          0.5133333333333333,
          0.45,
          0.44,
          0.39666666666666667,
          0.4633333333333333,
          0.4066666666666667,
          0.41,
          0.7566666666666667,
          0.7433333333333333,
          0.73,
          0.6566666666666666,
          0.6266666666666667,
          0.8766666666666667,
          0.9133333333333333,
          0.85,
          0.8966666666666666,
          0.8533333333333334,
          0.5333333333333333,
          0.5266666666666666,
          0.5366666666666666,
          0.53,
          0.56,
          0.49333333333333335,
          0.5133333333333333,
          0.5133333333333333,
          0.49,
          0.48,
          0.41,
          0.46,
          0.4266666666666667,
          0.44666666666666666,
          0.39666666666666667,
          0.7066666666666667,
          0.67,
          0.64,
          0.5966666666666667,
          0.7,
          0.84,
          0.8566666666666667,
          0.8766666666666667,
          0.8733333333333333,
          0.88
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop"
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxpoints": "all",
         "fillcolor": "rgba(255,255,255,0)",
         "hoveron": "points",
         "hovertemplate": "Model=LogisticRegression<br>Accuracy=%{x}<br>features=%{y}<extra></extra>",
         "legendgroup": "LogisticRegression",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "marker": {
          "color": "#00cc96"
         },
         "name": "LogisticRegression",
         "offsetgroup": "LogisticRegression",
         "orientation": "h",
         "pointpos": 0,
         "showlegend": true,
         "type": "box",
         "x": [
          0.46,
          0.48333333333333334,
          0.5,
          0.44,
          0.4633333333333333,
          0.5066666666666667,
          0.5366666666666666,
          0.5366666666666666,
          0.5133333333333333,
          0.49,
          0.4266666666666667,
          0.48333333333333334,
          0.5,
          0.4766666666666667,
          0.46,
          0.47333333333333333,
          0.4666666666666667,
          0.52,
          0.47,
          0.4866666666666667,
          0.43,
          0.43,
          0.4866666666666667,
          0.48333333333333334,
          0.4666666666666667,
          0.4633333333333333,
          0.52,
          0.5266666666666666,
          0.48333333333333334,
          0.47,
          0.4666666666666667,
          0.52,
          0.53,
          0.48333333333333334,
          0.48333333333333334,
          0.5133333333333333,
          0.49333333333333335,
          0.52,
          0.5133333333333333,
          0.47333333333333333,
          0.4666666666666667,
          0.5333333333333333,
          0.5733333333333334,
          0.48333333333333334,
          0.4633333333333333,
          0.5566666666666666,
          0.5633333333333334,
          0.6566666666666666,
          0.39,
          0.43666666666666665,
          0.48333333333333334,
          0.49666666666666665,
          0.47333333333333333,
          0.51,
          0.4866666666666667,
          0.5233333333333333,
          0.49,
          0.48,
          0.5133333333333333,
          0.49666666666666665,
          0.4866666666666667,
          0.48,
          0.52,
          0.49333333333333335,
          0.5166666666666667,
          0.51,
          0.44666666666666666,
          0.47333333333333333,
          0.49,
          0.5066666666666667,
          0.5,
          0.44666666666666666,
          0.4766666666666667,
          0.48333333333333334,
          0.5166666666666667,
          0.4533333333333333,
          0.5333333333333333,
          0.5333333333333333,
          0.4666666666666667,
          0.49,
          0.4866666666666667,
          0.5,
          0.5233333333333333,
          0.5066666666666667,
          0.5033333333333333,
          0.48,
          0.5166666666666667,
          0.53,
          0.5066666666666667,
          0.5066666666666667,
          0.5266666666666666,
          0.5233333333333333,
          0.5433333333333333,
          0.51,
          0.5766666666666667,
          0.5266666666666666,
          0.5933333333333334,
          0.5133333333333333,
          0.52,
          0.5133333333333333,
          0.5233333333333333,
          0.5033333333333333,
          0.4766666666666667,
          0.5,
          0.51,
          0.48,
          0.5033333333333333,
          0.4866666666666667,
          0.48333333333333334,
          0.5166666666666667,
          0.5466666666666666,
          0.5166666666666667,
          0.49,
          0.5366666666666666,
          0.56,
          0.51,
          0.4766666666666667,
          0.4766666666666667,
          0.5066666666666667,
          0.5233333333333333,
          0.54,
          0.49666666666666665,
          0.4866666666666667,
          0.5033333333333333,
          0.5233333333333333
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "all",
          "all",
          "all",
          "all",
          "all",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "text_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "rest_only",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "all_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop",
          "rest_plus_pop"
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "height": 600,
        "legend": {
         "title": {
          "text": "Model"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Swarm Plot of Model Accuracies Across Datasets"
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "features"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"baaa6fc8-d946-4121-a7fb-2cbaf382a36c\" class=\"plotly-graph-div\" style=\"height:600px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"baaa6fc8-d946-4121-a7fb-2cbaf382a36c\")) {                    Plotly.newPlot(                        \"baaa6fc8-d946-4121-a7fb-2cbaf382a36c\",                        [{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"Model=TabPFNClassifier\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003efeatures=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"TabPFNClassifier\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#636efa\"},\"name\":\"TabPFNClassifier\",\"offsetgroup\":\"TabPFNClassifier\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":true,\"x\":[0.5933333333333334,0.6733333333333333,0.6233333333333333,0.6533333333333333,0.6733333333333333,0.49333333333333335,0.5066666666666667,0.49666666666666665,0.4866666666666667,0.47333333333333333,0.45,0.4166666666666667,0.48333333333333334,0.4866666666666667,0.45,0.86,0.94,0.8933333333333333,0.92,0.9266666666666666,0.9633333333333334,0.97,0.9666666666666667,0.9466666666666667,0.9566666666666667,0.65,0.63,0.6666666666666666,0.62,0.6166666666666667,0.5,0.5066666666666667,0.5,0.5,0.5066666666666667,0.5133333333333333,0.49,0.5,0.5,0.47,0.8533333333333334,0.8766666666666667,0.9066666666666666,0.89,0.9033333333333333,0.9466666666666667,0.9733333333333334,0.99,0.98,0.9766666666666667,0.6,0.6533333333333333,0.61,0.6333333333333333,0.6033333333333334,0.48333333333333334,0.4766666666666667,0.4666666666666667,0.52,0.5066666666666667,0.48333333333333334,0.4766666666666667,0.51,0.4866666666666667,0.51,0.9033333333333333,0.91,0.8833333333333333,0.7533333333333333,0.87,0.9766666666666667,0.9666666666666667,0.9766666666666667,0.9533333333333334,0.9433333333333334,0.6233333333333333,0.6633333333333333,0.6233333333333333,0.55,0.6433333333333333,0.52,0.5166666666666667,0.52,0.5066666666666667,0.5066666666666667,0.47,0.51,0.47333333333333333,0.5066666666666667,0.5066666666666667,0.82,0.91,0.8466666666666667,0.86,0.8766666666666667,0.97,0.9666666666666667,0.9533333333333334,0.9566666666666667,0.9366666666666666,0.59,0.6566666666666666,0.5866666666666667,0.58,0.65,0.5266666666666666,0.5166666666666667,0.5033333333333333,0.5066666666666667,0.5366666666666666,0.5266666666666666,0.53,0.49666666666666665,0.54,0.57,0.76,0.8666666666666667,0.92,0.7733333333333333,0.91,0.9666666666666667,0.92,0.9666666666666667,0.9666666666666667,0.97],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\"],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"Model=GradientBoostingClassifier\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003efeatures=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"GradientBoostingClassifier\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#EF553B\"},\"name\":\"GradientBoostingClassifier\",\"offsetgroup\":\"GradientBoostingClassifier\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":true,\"x\":[0.5266666666666666,0.52,0.5766666666666667,0.5633333333333334,0.5666666666666667,0.45,0.47333333333333333,0.49333333333333335,0.5066666666666667,0.5166666666666667,0.35333333333333333,0.38333333333333336,0.43,0.37666666666666665,0.41333333333333333,0.73,0.74,0.5933333333333334,0.6533333333333333,0.73,0.8966666666666666,0.9133333333333333,0.9066666666666666,0.8766666666666667,0.8866666666666667,0.5466666666666666,0.54,0.57,0.49,0.52,0.48,0.5066666666666667,0.5066666666666667,0.48,0.4666666666666667,0.38666666666666666,0.39666666666666667,0.38,0.4,0.38666666666666666,0.6366666666666667,0.7133333333333334,0.74,0.6566666666666666,0.7266666666666667,0.8733333333333333,0.8833333333333333,0.87,0.8766666666666667,0.8866666666666667,0.5633333333333334,0.52,0.5,0.58,0.51,0.5333333333333333,0.47,0.49666666666666665,0.47333333333333333,0.5066666666666667,0.39666666666666667,0.39666666666666667,0.42,0.4166666666666667,0.37333333333333335,0.6833333333333333,0.7266666666666667,0.7066666666666667,0.6966666666666667,0.67,0.8833333333333333,0.9,0.8733333333333333,0.8666666666666667,0.87,0.54,0.58,0.5466666666666666,0.5633333333333334,0.49666666666666665,0.53,0.5133333333333333,0.54,0.5133333333333333,0.45,0.44,0.39666666666666667,0.4633333333333333,0.4066666666666667,0.41,0.7566666666666667,0.7433333333333333,0.73,0.6566666666666666,0.6266666666666667,0.8766666666666667,0.9133333333333333,0.85,0.8966666666666666,0.8533333333333334,0.5333333333333333,0.5266666666666666,0.5366666666666666,0.53,0.56,0.49333333333333335,0.5133333333333333,0.5133333333333333,0.49,0.48,0.41,0.46,0.4266666666666667,0.44666666666666666,0.39666666666666667,0.7066666666666667,0.67,0.64,0.5966666666666667,0.7,0.84,0.8566666666666667,0.8766666666666667,0.8733333333333333,0.88],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\"],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"fillcolor\":\"rgba(255,255,255,0)\",\"hoveron\":\"points\",\"hovertemplate\":\"Model=LogisticRegression\\u003cbr\\u003eAccuracy=%{x}\\u003cbr\\u003efeatures=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"LogisticRegression\",\"line\":{\"color\":\"rgba(255,255,255,0)\"},\"marker\":{\"color\":\"#00cc96\"},\"name\":\"LogisticRegression\",\"offsetgroup\":\"LogisticRegression\",\"orientation\":\"h\",\"pointpos\":0,\"showlegend\":true,\"x\":[0.46,0.48333333333333334,0.5,0.44,0.4633333333333333,0.5066666666666667,0.5366666666666666,0.5366666666666666,0.5133333333333333,0.49,0.4266666666666667,0.48333333333333334,0.5,0.4766666666666667,0.46,0.47333333333333333,0.4666666666666667,0.52,0.47,0.4866666666666667,0.43,0.43,0.4866666666666667,0.48333333333333334,0.4666666666666667,0.4633333333333333,0.52,0.5266666666666666,0.48333333333333334,0.47,0.4666666666666667,0.52,0.53,0.48333333333333334,0.48333333333333334,0.5133333333333333,0.49333333333333335,0.52,0.5133333333333333,0.47333333333333333,0.4666666666666667,0.5333333333333333,0.5733333333333334,0.48333333333333334,0.4633333333333333,0.5566666666666666,0.5633333333333334,0.6566666666666666,0.39,0.43666666666666665,0.48333333333333334,0.49666666666666665,0.47333333333333333,0.51,0.4866666666666667,0.5233333333333333,0.49,0.48,0.5133333333333333,0.49666666666666665,0.4866666666666667,0.48,0.52,0.49333333333333335,0.5166666666666667,0.51,0.44666666666666666,0.47333333333333333,0.49,0.5066666666666667,0.5,0.44666666666666666,0.4766666666666667,0.48333333333333334,0.5166666666666667,0.4533333333333333,0.5333333333333333,0.5333333333333333,0.4666666666666667,0.49,0.4866666666666667,0.5,0.5233333333333333,0.5066666666666667,0.5033333333333333,0.48,0.5166666666666667,0.53,0.5066666666666667,0.5066666666666667,0.5266666666666666,0.5233333333333333,0.5433333333333333,0.51,0.5766666666666667,0.5266666666666666,0.5933333333333334,0.5133333333333333,0.52,0.5133333333333333,0.5233333333333333,0.5033333333333333,0.4766666666666667,0.5,0.51,0.48,0.5033333333333333,0.4866666666666667,0.48333333333333334,0.5166666666666667,0.5466666666666666,0.5166666666666667,0.49,0.5366666666666666,0.56,0.51,0.4766666666666667,0.4766666666666667,0.5066666666666667,0.5233333333333333,0.54,0.49666666666666665,0.4866666666666667,0.5033333333333333,0.5233333333333333],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"all\",\"all\",\"all\",\"all\",\"all\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"text_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"rest_only\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"all_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\",\"rest_plus_pop\"],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Accuracy\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"features\"}},\"legend\":{\"title\":{\"text\":\"Model\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Swarm Plot of Model Accuracies Across Datasets\"},\"boxmode\":\"group\",\"height\":600,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('baaa6fc8-d946-4121-a7fb-2cbaf382a36c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "#melted_results = results.groupby(['dataset', 'model', 'dim_reduction', 'encoding', \"features\"]).mean().reset_index()\n",
    "melted_results = results\n",
    "#melted_results = results.explode('accuracy')\n",
    "#melted_results['accuracy'] = melted_results['accuracy'].astype(float)\n",
    "#melted_results = melted_results[melted_results['encoding'] == 'lm__all-MiniLM-L12-v2']\n",
    "print(len(melted_results))\n",
    "\n",
    "# Creating the swarmplot\n",
    "# plt.figure(figsize=(15, 20))\n",
    "# sns.swarmplot(data=melted_results, x='accuracy', y='dataset', hue='model', dodge=True)\n",
    "# plt.title('Swarm Plot of Model Accuracies Across Datasets')\n",
    "# plt.xlabel('Accuracy')\n",
    "# plt.ylabel('Dataset')\n",
    "# plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.show()\n",
    "# Create the plot\n",
    "\n",
    "# Create the plot\n",
    "fig = px.strip(\n",
    "    data_frame=melted_results,\n",
    "    x=\"accuracy\",\n",
    "    y=\"features\",\n",
    "    color=\"model\",\n",
    "    #color=\"dim_reduction\",\n",
    "    title=\"Swarm Plot of Model Accuracies Across Datasets\",\n",
    "    labels={\"accuracy\": \"Accuracy\", \"dataset\": \"Dataset\", \"model\": \"Model\"},\n",
    "    height=600,\n",
    "    width=900,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>encoding</th>\n",
       "      <th>dim_reduction</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pop</td>\n",
       "      <td>lm__all-distilroberta-v1</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>TabPFNClassifier</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pop</td>\n",
       "      <td>lm__all-distilroberta-v1</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>TabPFNClassifier</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pop</td>\n",
       "      <td>lm__all-distilroberta-v1</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>TabPFNClassifier</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pop</td>\n",
       "      <td>lm__all-distilroberta-v1</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>TabPFNClassifier</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pop</td>\n",
       "      <td>lm__all-distilroberta-v1</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>TabPFNClassifier</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pop</td>\n",
       "      <td>lm__all-distilroberta-v1</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>all_plus_pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pop</td>\n",
       "      <td>lm__all-distilroberta-v1</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>all_plus_pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pop</td>\n",
       "      <td>lm__all-distilroberta-v1</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>all_plus_pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pop</td>\n",
       "      <td>lm__all-distilroberta-v1</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>all_plus_pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pop</td>\n",
       "      <td>lm__all-distilroberta-v1</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>all_plus_pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                  encoding dim_reduction               model  \\\n",
       "0      pop  lm__all-distilroberta-v1        PCA_10    TabPFNClassifier   \n",
       "1      pop  lm__all-distilroberta-v1        PCA_10    TabPFNClassifier   \n",
       "2      pop  lm__all-distilroberta-v1        PCA_10    TabPFNClassifier   \n",
       "3      pop  lm__all-distilroberta-v1        PCA_10    TabPFNClassifier   \n",
       "4      pop  lm__all-distilroberta-v1        PCA_10    TabPFNClassifier   \n",
       "..     ...                       ...           ...                 ...   \n",
       "0      pop  lm__all-distilroberta-v1        PCA_10  LogisticRegression   \n",
       "1      pop  lm__all-distilroberta-v1        PCA_10  LogisticRegression   \n",
       "2      pop  lm__all-distilroberta-v1        PCA_10  LogisticRegression   \n",
       "3      pop  lm__all-distilroberta-v1        PCA_10  LogisticRegression   \n",
       "4      pop  lm__all-distilroberta-v1        PCA_10  LogisticRegression   \n",
       "\n",
       "    accuracy      features  \n",
       "0   0.586667           all  \n",
       "1   0.626667           all  \n",
       "2   0.646667           all  \n",
       "3   0.553333           all  \n",
       "4   0.640000           all  \n",
       "..       ...           ...  \n",
       "0   0.466667  all_plus_pop  \n",
       "1   0.490000  all_plus_pop  \n",
       "2   0.473333  all_plus_pop  \n",
       "3   0.483333  all_plus_pop  \n",
       "4   0.516667  all_plus_pop  \n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
